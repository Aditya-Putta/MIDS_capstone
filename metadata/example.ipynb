{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Generation of Intrinio based Financial Data - Shankar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/NatarajanShankar/UC_Berkeley/Final_term/Capstone/W210/MIDS_capstone/metadata\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from api_key import INTRINIO_USERNAME\n",
    "from api_key import INTRINIO_PASSWORD             \n",
    "\n",
    "import md_intrinio_client\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from md_intrinio_client import intrinio_get_company_metadata\n",
    "from md_intrinio_client import intrinio_get_company_financials\n",
    "from md_intrinio_client import intrinio_get_company_financials_csv\n",
    "from md_intrinio_client import get_SandP_metadata\n",
    "from md_intrinio_client import test_SandP_metadata\n",
    "from finsymbols import symbols\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import finsymbols\n",
    "import ast\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json \n",
    "SandP500 = {}\n",
    "companyList = []\n",
    "with open(\"SandP500_symbols.txt\", \"r\") as fr:\n",
    "            for line in fr:\n",
    "                    company = json.loads(line)\n",
    "                    SandP500[company[\"symbol\"]] = line\n",
    "                    companyList.append(company[\"symbol\"])\n",
    "\n",
    "tickerchunks = [companyList[x:x+100] for x in xrange(0, len(companyList), 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[u'CTL', u'CERN', u'CF', u'SCHW', u'CHTR', u'CHK', u'CVX', u'CMG', u'CB', u'CHD', u'CI', u'XEC', u'CINF', u'CTAS', u'CSCO', u'C', u'CFG', u'CTXS', u'CLX', u'CME', u'CMS', u'COH', u'KO', u'CTSH', u'CL', u'CMCSA', u'CMA', u'CAG', u'CXO', u'COP', u'ED', u'STZ', u'COO', u'GLW', u'COST', u'COTY', u'CCI', u'CSRA', u'CSX', u'CMI', u'CVS', u'DHI', u'DHR', u'DRI', u'DVA', u'DE', u'DLPH', u'DAL', u'XRAY', u'DVN', u'DLR', u'DFS', u'DISCA', u'DISCK', u'DISH', u'DG', u'DLTR', u'D', u'DOV', u'DWDP', u'DPS', u'DTE', u'DRE', u'DUK', u'DXC', u'ETFC', u'EMN', u'ETN', u'EBAY', u'ECL', u'EIX', u'EW', u'EA', u'EMR', u'ETR', u'EVHC', u'EOG', u'EQT', u'EFX', u'EQIX', u'EQR', u'ESS', u'EL', u'ES', u'RE', u'EXC', u'EXPE', u'EXPD', u'ESRX', u'EXR', u'XOM', u'FFIV', u'FB', u'FAST', u'FRT', u'FDX', u'FIS', u'FITB', u'FE', u'FISV']\n"
     ]
    }
   ],
   "source": [
    "print(len(tickerchunks[1]))\n",
    "print((tickerchunks[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_intrinio_get_company_financials(symbol, year, quarter):\n",
    "        # Get the latest FY Income Statement for \"symbol\"\n",
    "        # 'type': 'FY'\n",
    "        cleanedupdata = {}\n",
    "        base_url = \"https://api.intrinio.com\"\n",
    "        request_url = base_url + \"/financials/standardized\"\n",
    "        query_params = {\n",
    "                'ticker': symbol,\n",
    "                'statement': 'income_statement',\n",
    "                'fiscal_year' : str(year),\n",
    "                'fiscal_period' : quarter\n",
    "        }\n",
    "\n",
    "        response = requests.get(request_url, params=query_params, auth=(INTRINIO_USERNAME, INTRINIO_PASSWORD))\n",
    "        if response.status_code == 401: print(\"Unauthorized! Check your username and password.\"); exit()\n",
    "\n",
    "        if response.status_code == 429:\n",
    "            print(\"API query limit reached\")\n",
    "            return\n",
    "        data = response.json()['data']\n",
    "\n",
    "\n",
    "        for row in data:\n",
    "                tag = row['tag']\n",
    "                value = row['value']\n",
    "                cleanedupdata[\"AASYMBOL\"] = symbol\n",
    "                cleanedupdata[\"ABYEAR\"] = year\n",
    "                cleanedupdata[\"ACPeriod\"] = quarter\n",
    "                cleanedupdata[tag] = value\n",
    "\n",
    "        datalist=[]\n",
    "        for key, value in sorted(cleanedupdata.items()):\n",
    "            datalist.append(str(value))\n",
    "        \n",
    "\n",
    "        return(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updated_cleanupdata(cleanedupdata):\n",
    "    newData = {}\n",
    "    newData['AASYMBOL'] = cleanedupdata['AASYMBOL']\n",
    "    newData['ABYEAR'] = cleanedupdata['ABYEAR']\n",
    "    newData['ACPeriod'] = cleanedupdata['ACPeriod']\n",
    "    newData['basicdilutedeps'] = cleanedupdata.get('basicdilutedeps', 0.0)\n",
    "    newData['basiceps'] = cleanedupdata.get('basiceps', 0.0)\n",
    "    \n",
    "    newData['cashdividendspershare'] = cleanedupdata.get('cashdividendspershare', 0.0)\n",
    "    newData['dilutedeps'] = cleanedupdata.get('dilutedeps', 0.0)\n",
    "    newData['incometaxexpense'] = cleanedupdata.get('incometaxexpense', 0.0)\n",
    "    newData['netincome'] = cleanedupdata.get('netincome', 0.0)\n",
    "    newData['netincomecontinuing'] = cleanedupdata.get('netincomecontinuing', 0.0)\n",
    "    \n",
    "    newData['netincomediscontinued'] = cleanedupdata.get('netincomediscontinued', 0.0)\n",
    "    newData['netincometocommon'] = cleanedupdata.get('netincometocommon', 0.0)\n",
    "    newData['netincometononcontrollinginterest'] = cleanedupdata.get('netincometononcontrollinginterest', 0.0)\n",
    "    newData['operatingcostofrevenue'] = cleanedupdata.get('operatingcostofrevenue', 0.0)\n",
    "    newData['operatingrevenue'] = cleanedupdata.get('operatingrevenue', 0.0)\n",
    "    \n",
    "    newData['othercostofrevenue'] = cleanedupdata.get('othercostofrevenue', 0.0)\n",
    "    newData['otherincome'] = cleanedupdata.get('otherincome', 0.0)\n",
    "    newData['preferreddividends'] = cleanedupdata.get('preferreddividends', 0.0)\n",
    "    newData['sgaexpense'] = cleanedupdata.get('sgaexpense', 0.0)\n",
    "    newData['totalcostofrevenue'] = cleanedupdata.get('totalcostofrevenue', 0.0)\n",
    "    \n",
    "    newData['totalgrossprofit'] = cleanedupdata.get('totalgrossprofit', 0.0)\n",
    "    newData['totalinterestexpense'] = cleanedupdata.get('totalinterestexpense', 0.0)\n",
    "    newData['totaloperatingexpenses'] = cleanedupdata.get('totaloperatingexpenses', 0.0)\n",
    "    newData['totaloperatingincome'] = cleanedupdata.get('totaloperatingincome', 0.0)\n",
    "    newData['totalotherincome'] = cleanedupdata.get('totalotherincome', 0.0)\n",
    "    \n",
    "    newData['totalpretaxincome'] = cleanedupdata.get('totalpretaxincome', 0.0)\n",
    "    newData['totalrevenue'] = cleanedupdata.get('totalrevenue', 0.0)\n",
    "    newData['weightedavebasicdilutedsharesos'] = cleanedupdata.get('weightedavebasicdilutedsharesos', 0.0)\n",
    "    newData['weightedavebasicsharesos'] = cleanedupdata.get('weightedavebasicsharesos', 0.0)\n",
    "    newData['weightedavedilutedsharesos'] = cleanedupdata.get('weightedavedilutedsharesos', 0.0)\n",
    "    \n",
    "    #newData[] = cleanedupdata.get(, 0.0)\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "ticker,year,quarter,basicdilutedeps,basiceps,cashdividendspershare,dilutedeps,incometaxexpense,netincome,netincomecontinuing,netincomediscontinued,netincometocommon,netincometononcontrollinginterest,totalcostofrevenue,operatingcostofrevenue,operatingrevenue,othercostofrevenue,otherincome,preferreddividends,sgaexpense,totalgrossprofit,totalinterestexpense,totaloperatingexpenses,totaloperatingincome,totalotherincome,totalpretaxincome,totalrevenue,weightedavebasicdilutedsharesos,weightedavebasicsharesos,weightedavedilutedsharesos\n"
     ]
    }
   ],
   "source": [
    "attributes = [\"ticker\", \"year\", \"quarter\", \"basicdilutedeps\", \"basiceps\",\n",
    "              'cashdividendspershare', 'dilutedeps', 'incometaxexpense', 'netincome', 'netincomecontinuing',\n",
    "              'netincomediscontinued', 'netincometocommon', 'netincometononcontrollinginterest', 'totalcostofrevenue', \n",
    "                  'operatingcostofrevenue', 'operatingrevenue',\n",
    "              'othercostofrevenue', 'otherincome', 'preferreddividends', 'sgaexpense', \n",
    "              'totalgrossprofit', 'totalinterestexpense', 'totaloperatingexpenses', 'totaloperatingincome', 'totalotherincome', \n",
    "              'totalpretaxincome', 'totalrevenue', 'weightedavebasicdilutedsharesos', 'weightedavebasicsharesos', 'weightedavedilutedsharesos'\n",
    "                 ]\n",
    "print(len(attributes))\n",
    "\n",
    "xx = \",\".join(attributes)\n",
    "print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updated_intrinio_get_company_financials(symbol, year, quarter):\n",
    "        # Get the latest FY Income Statement for \"symbol\"\n",
    "        # 'type': 'FY'\n",
    "        cleanedupdata = {}\n",
    "        base_url = \"https://api.intrinio.com\"\n",
    "        request_url = base_url + \"/financials/standardized\"\n",
    "        query_params = {\n",
    "                'ticker': symbol,\n",
    "                'statement': 'income_statement',\n",
    "                'fiscal_year' : str(year),\n",
    "                'fiscal_period' : quarter\n",
    "        }\n",
    "\n",
    "        response = requests.get(request_url, params=query_params, auth=(INTRINIO_USERNAME, INTRINIO_PASSWORD))\n",
    "        if response.status_code == 401: print(\"Unauthorized! Check your username and password.\"); exit()\n",
    "\n",
    "        if response.status_code == 429:\n",
    "            print(\"API query limit reached\")\n",
    "            return\n",
    "        data = response.json()['data']\n",
    "\n",
    "        #print(data['basicdilutedeps'])\n",
    "        for row in data:\n",
    "                #print(row)\n",
    "                tag = row['tag']\n",
    "                value = row['value']\n",
    "\n",
    "                cleanedupdata[tag] = value\n",
    "\n",
    "        datalist=[]\n",
    "        attr = []\n",
    "        cleanedupdata[\"AASYMBOL\"] = symbol\n",
    "        cleanedupdata[\"ABYEAR\"] = year\n",
    "        cleanedupdata[\"ACPeriod\"] = quarter\n",
    "        cleanedupdata = updated_cleanupdata(cleanedupdata)\n",
    "        for key, value in sorted(cleanedupdata.items()):\n",
    "            datalist.append(str(value))\n",
    "            attr.append(str(key))\n",
    " \n",
    "        return(datalist, attr)\n",
    "#data = intrinio_get_company_financials('GE', '2010', 'FY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_financial_data():\n",
    "    SandP500 = {}\n",
    "    companyList = []\n",
    "    with open(\"SandP500_symbols.txt\", \"r\") as fr:\n",
    "            for line in fr:\n",
    "                    company = json.loads(line)\n",
    "                    SandP500[company[\"symbol\"]] = line\n",
    "                    companyList.append(company[\"symbol\"])\n",
    "\n",
    "    tickerchunks = [companyList[x:x+100] for x in xrange(0, len(companyList), 100)]\n",
    "\n",
    "\n",
    "    years = [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017]\n",
    "    quarters = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"FY\"]\n",
    "    #years = [2010]\n",
    "    #quarters = [\"Q1\", \"Q2\"]\n",
    "    #companies = [\"GE\", \"CSCO\", \"GOOG\", \"FACE\"]\n",
    "\n",
    "    bigDict = {}\n",
    "\n",
    "    attributes = [\"ticker\", \"year\", \"quarter\", \"basicdilutedeps\", \"basiceps\",\n",
    "              'cashdividendspershare', 'dilutedeps', 'incometaxexpense', 'netincome', 'netincomecontinuing',\n",
    "              'netincomediscontinued', 'netincometocommon', 'netincometononcontrollinginterest', 'totalcostofrevenue', \n",
    "                  'operatingcostofrevenue', 'operatingrevenue',\n",
    "              'othercostofrevenue', 'otherincome', 'preferreddividends', 'sgaexpense', \n",
    "              'totalgrossprofit', 'totalinterestexpense', 'totaloperatingexpenses', 'totaloperatingincome', 'totalotherincome', \n",
    "              'totalpretaxincome', 'totalrevenue', 'weightedavebasicdilutedsharesos', 'weightedavebasicsharesos', 'weightedavedilutedsharesos'\n",
    "                 ]\n",
    "    print(len(attributes))\n",
    "\n",
    "    xx = \",\".join(attributes) + \"\\n\"\n",
    "\n",
    "    # tickerchunks[1], tickerchunks[2], tickerchunks[3] and tickerchunks[5] are done\n",
    "    # \n",
    "    loopIndex = 0\n",
    "    for company in tickerchunks[1]:\n",
    "        with open(\"./revenue/\"+company+\"_Financials_by_Quarter.csv\", 'w') as fw:\n",
    "            fw.write(xx)\n",
    "            print(\"working on {} - {}\".format(company, loopIndex))\n",
    "#             if loopIndex > 2:\n",
    "#                 break\n",
    "            loopIndex += 1\n",
    "            #print(\"working on company {}\".format(company))\n",
    "            for year in years:\n",
    "\n",
    "                #print(\"working on year {}\".format(year))\n",
    "                for quarter in quarters:\n",
    "                    #print(\"working on quarter {}\".format(quarter))\n",
    "\n",
    "                    data, _ = updated_intrinio_get_company_financials(company, str(year), quarter)\n",
    "                    yy = \",\".join(data)\n",
    "                    yy +=\"\\n\"\n",
    "\n",
    "                    fw.write(yy)\n",
    "\n",
    "            print(\"DONE with {}\".format(company))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "working on CTL - 0\n",
      "DONE with CTL\n",
      "working on CERN - 1\n",
      "DONE with CERN\n",
      "working on CF - 2\n",
      "DONE with CF\n",
      "working on SCHW - 3\n",
      "DONE with SCHW\n",
      "working on CHTR - 4\n",
      "DONE with CHTR\n",
      "working on CHK - 5\n",
      "DONE with CHK\n",
      "working on CVX - 6\n",
      "DONE with CVX\n",
      "working on CMG - 7\n",
      "DONE with CMG\n",
      "working on CB - 8\n",
      "DONE with CB\n",
      "working on CHD - 9\n",
      "DONE with CHD\n",
      "working on CI - 10\n",
      "DONE with CI\n",
      "working on XEC - 11\n",
      "DONE with XEC\n",
      "working on CINF - 12\n",
      "DONE with CINF\n",
      "working on CTAS - 13\n",
      "DONE with CTAS\n",
      "working on CSCO - 14\n",
      "DONE with CSCO\n",
      "working on C - 15\n",
      "DONE with C\n",
      "working on CFG - 16\n",
      "DONE with CFG\n",
      "working on CTXS - 17\n",
      "DONE with CTXS\n",
      "working on CLX - 18\n",
      "DONE with CLX\n",
      "working on CME - 19\n",
      "DONE with CME\n",
      "working on CMS - 20\n",
      "DONE with CMS\n",
      "working on COH - 21\n",
      "DONE with COH\n",
      "working on KO - 22\n",
      "DONE with KO\n",
      "working on CTSH - 23\n",
      "DONE with CTSH\n",
      "working on CL - 24\n",
      "DONE with CL\n",
      "working on CMCSA - 25\n",
      "DONE with CMCSA\n",
      "working on CMA - 26\n",
      "DONE with CMA\n",
      "working on CAG - 27\n",
      "DONE with CAG\n",
      "working on CXO - 28\n",
      "DONE with CXO\n",
      "working on COP - 29\n",
      "DONE with COP\n",
      "working on ED - 30\n",
      "DONE with ED\n",
      "working on STZ - 31\n",
      "DONE with STZ\n",
      "working on COO - 32\n",
      "DONE with COO\n",
      "working on GLW - 33\n",
      "DONE with GLW\n",
      "working on COST - 34\n",
      "DONE with COST\n",
      "working on COTY - 35\n",
      "DONE with COTY\n",
      "working on CCI - 36\n",
      "DONE with CCI\n",
      "working on CSRA - 37\n",
      "DONE with CSRA\n",
      "working on CSX - 38\n",
      "DONE with CSX\n",
      "working on CMI - 39\n",
      "DONE with CMI\n",
      "working on CVS - 40\n",
      "DONE with CVS\n",
      "working on DHI - 41\n",
      "DONE with DHI\n",
      "working on DHR - 42\n",
      "DONE with DHR\n",
      "working on DRI - 43\n",
      "DONE with DRI\n",
      "working on DVA - 44\n",
      "DONE with DVA\n",
      "working on DE - 45\n",
      "DONE with DE\n",
      "working on DLPH - 46\n",
      "DONE with DLPH\n",
      "working on DAL - 47\n",
      "DONE with DAL\n",
      "working on XRAY - 48\n",
      "DONE with XRAY\n",
      "working on DVN - 49\n",
      "DONE with DVN\n",
      "working on DLR - 50\n",
      "DONE with DLR\n",
      "working on DFS - 51\n",
      "DONE with DFS\n",
      "working on DISCA - 52\n",
      "DONE with DISCA\n",
      "working on DISCK - 53\n",
      "DONE with DISCK\n",
      "working on DISH - 54\n",
      "DONE with DISH\n",
      "working on DG - 55\n",
      "DONE with DG\n",
      "working on DLTR - 56\n",
      "DONE with DLTR\n",
      "working on D - 57\n",
      "DONE with D\n",
      "working on DOV - 58\n",
      "DONE with DOV\n",
      "working on DWDP - 59\n",
      "DONE with DWDP\n",
      "working on DPS - 60\n",
      "DONE with DPS\n",
      "working on DTE - 61\n",
      "DONE with DTE\n",
      "working on DRE - 62\n",
      "DONE with DRE\n",
      "working on DUK - 63\n",
      "DONE with DUK\n",
      "working on DXC - 64\n",
      "DONE with DXC\n",
      "working on ETFC - 65\n",
      "DONE with ETFC\n",
      "working on EMN - 66\n",
      "DONE with EMN\n",
      "working on ETN - 67\n",
      "DONE with ETN\n",
      "working on EBAY - 68\n",
      "DONE with EBAY\n",
      "working on ECL - 69\n",
      "DONE with ECL\n",
      "working on EIX - 70\n",
      "DONE with EIX\n",
      "working on EW - 71\n",
      "DONE with EW\n",
      "working on EA - 72\n",
      "DONE with EA\n",
      "working on EMR - 73\n",
      "DONE with EMR\n",
      "working on ETR - 74\n",
      "DONE with ETR\n",
      "working on EVHC - 75\n",
      "DONE with EVHC\n",
      "working on EOG - 76\n",
      "DONE with EOG\n",
      "working on EQT - 77\n",
      "DONE with EQT\n",
      "working on EFX - 78\n",
      "DONE with EFX\n",
      "working on EQIX - 79\n",
      "DONE with EQIX\n",
      "working on EQR - 80\n",
      "DONE with EQR\n",
      "working on ESS - 81\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7fcc233d0b1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_financial_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-85328ab93692>\u001b[0m in \u001b[0;36mgenerate_financial_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0;31m#print(\"working on quarter {}\".format(quarter))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdated_intrinio_get_company_financials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompany\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquarter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                     \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                     \u001b[0myy\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-43da7b67ad89>\u001b[0m in \u001b[0;36mupdated_intrinio_get_company_financials\u001b[0;34m(symbol, year, quarter)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"API query limit reached\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#print(data['basicdilutedeps'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/requests/models.pyc\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    890\u001b[0m                     \u001b[0;31m# used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/simplejson/__init__.pyc\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, use_decimal, **kw)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mparse_constant\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobject_pairs_hook\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m             and not use_decimal and not kw):\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/simplejson/decoder.pyc\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w, _PY3)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_PY3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/simplejson/decoder.pyc\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx, _w, _PY3)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mord0\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0xef\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'\\xef\\xbb\\xbf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "generate_financial_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/NatarajanShankar/UC_Berkeley/Final_term/Capstone/W210/MIDS_capstone/metadata\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/NatarajanShankar/UC_Berkeley/Final_term/Capstone/W210/MIDS_capstone/metadata\")\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import ast\n",
    "\n",
    "def convert_json_to_csv():\n",
    "    companyDict = {}\n",
    "    os.chdir(\"./data\")\n",
    "    #print(\"got here\")\n",
    "    for datafile in glob.glob(\"*Financials*.json\"):\n",
    "        #print(datafile)\n",
    "        with open(datafile, \"r\") as fr:\n",
    "            #print (\"Processing {}\".format(datafile))\n",
    "            for line in fr:\n",
    "                companyDict = ast.literal_eval(line)\n",
    "                \n",
    "                # Save company ticker\n",
    "                for company, companyvalue in companyDict.items():\n",
    "                    #print(\"Company is\")\n",
    "                    #print(\"{}\".format(company, end=''))\n",
    "                    # For every year subset\n",
    "                    if isinstance(companyvalue, dict):\n",
    "                        for year, yearvalue in companyvalue.items():\n",
    "                            #print(\"Year is\")\n",
    "                            #print(\"{}\".format(year, end=''))\n",
    "                            # Look at the corresponding quarter\n",
    "                            if isinstance(yearvalue, dict):\n",
    "                                datalist=[]\n",
    "                                # Look at company quarter\n",
    "                                for quarter, quartervalue in yearvalue.items():\n",
    "                                    #print(\"Quarter is\")\n",
    "                                    #print(\"{}\".format(quarter, end=''))\n",
    "                                    for financialdata in quartervalue.values():\n",
    "                                        datalist.append(financialdata)\n",
    "                                    \n",
    "                                    if len(datalist) > 21:\n",
    "                                        datalist[14] = \"IGNORE\"\n",
    "                                        datalist[21] = \"IGNORE\"\n",
    "                                    \n",
    "                                    if len(datalist) == 2:\n",
    "                                        datalist[0] = \"\"\n",
    "                                        datalist[1] = \"\"\n",
    "                                    print(\"{},{},{},{}\".format(company, year, quarter, \",\".join(datalist), end=''))\n",
    "                                    \n",
    "                                    datalist = []\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLIR,2010,Q1,\n",
      "FLIR,2010,Q4,\n"
     ]
    }
   ],
   "source": [
    "convert_json_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_company_financial_data_all(symbol):\n",
    "    companyDict = {}\n",
    "    with open(\"./data/Financials.json\", \"r\") as fp:\n",
    "        #companyDict = json.load(fp)\n",
    "        for line in fp:\n",
    "            companyDict = ast.literal_eval(line)\n",
    "\n",
    "        for ticker in companyDict.keys():\n",
    "            if ticker == symbol:\n",
    "                print symbol, companyDict[symbol]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_company_financial_data_all(\"GE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_company_financial_data_by_year(symbol, year):\n",
    "    companyDict = {}\n",
    "    with open(\"./data/Financials.json\", \"r\") as fp:\n",
    "        #companyDict = json.load(fp)\n",
    "        for line in fp:\n",
    "            companyDict = ast.literal_eval(line)\n",
    "\n",
    "        for ticker in companyDict.keys():\n",
    "            if ticker == symbol:\n",
    "                print symbol, companyDict[symbol][year]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_company_financial_data_by_year(\"GE\", \"2014\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_company_financial_data_by_year_and_attr(symbol, year, attribute):\n",
    "    companyDict = {}\n",
    "    with open(\"./data/Financials.json\", \"r\") as fp:\n",
    "        #companyDict = json.load(fp)\n",
    "        for line in fp:\n",
    "            companyDict = ast.literal_eval(line)\n",
    "\n",
    "        for ticker in companyDict.keys():\n",
    "            if ticker == symbol:\n",
    "                print symbol, companyDict[symbol][year][attribute]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_company_financial_data_by_year_and_attr(\"GE\", \"2014\", \"basiceps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_company_financial_data_csv(symbol):\n",
    "    companyDict = {}\n",
    "    with open(\"./data/Financials.json\", \"r\") as fp:\n",
    "        for line in fp:\n",
    "            companyDict = ast.literal_eval(line)\n",
    "            \n",
    "        for ticker in companyDict.keys():\n",
    "            if ticker == symbol:\n",
    "                print symbol, companyDict\n",
    "            \n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
