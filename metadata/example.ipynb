{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Generation of Intrinio based Financial Data - Shankar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/NatarajanShankar/UC_Berkeley/Final_term/Capstone/W210/MIDS_capstone/metadata\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from api_key import INTRINIO_USERNAME\n",
    "from api_key import INTRINIO_PASSWORD             \n",
    "\n",
    "import md_intrinio_client\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from md_intrinio_client import intrinio_get_company_metadata\n",
    "from md_intrinio_client import intrinio_get_company_financials\n",
    "from md_intrinio_client import intrinio_get_company_financials_csv\n",
    "from md_intrinio_client import get_SandP_metadata\n",
    "from md_intrinio_client import test_SandP_metadata\n",
    "from finsymbols import symbols\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import finsymbols\n",
    "import ast\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json \n",
    "SandP500 = {}\n",
    "companyList = []\n",
    "with open(\"SandP500_symbols.txt\", \"r\") as fr:\n",
    "            for line in fr:\n",
    "                    company = json.loads(line)\n",
    "                    SandP500[company[\"symbol\"]] = line\n",
    "                    companyList.append(company[\"symbol\"])\n",
    "\n",
    "tickerchunks = [companyList[x:x+95] for x in xrange(0, len(companyList), 95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(tickerchunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "[u'CBG', u'CBS', u'CELG', u'CNC', u'CNP', u'CTL', u'CERN', u'CF', u'SCHW', u'CHTR', u'CHK', u'CVX', u'CMG', u'CB', u'CHD', u'CI', u'XEC', u'CINF', u'CTAS', u'CSCO', u'C', u'CFG', u'CTXS', u'CLX', u'CME', u'CMS', u'COH', u'KO', u'CTSH', u'CL', u'CMCSA', u'CMA', u'CAG', u'CXO', u'COP', u'ED', u'STZ', u'COO', u'GLW', u'COST', u'COTY', u'CCI', u'CSRA', u'CSX', u'CMI', u'CVS', u'DHI', u'DHR', u'DRI', u'DVA', u'DE', u'DLPH', u'DAL', u'XRAY', u'DVN', u'DLR', u'DFS', u'DISCA', u'DISCK', u'DISH', u'DG', u'DLTR', u'D', u'DOV', u'DWDP', u'DPS', u'DTE', u'DRE', u'DUK', u'DXC', u'ETFC', u'EMN', u'ETN', u'EBAY', u'ECL', u'EIX', u'EW', u'EA', u'EMR', u'ETR', u'EVHC', u'EOG', u'EQT', u'EFX', u'EQIX', u'EQR', u'ESS', u'EL', u'ES', u'RE', u'EXC', u'EXPE', u'EXPD', u'ESRX', u'EXR']\n"
     ]
    }
   ],
   "source": [
    "print(len(tickerchunks[1]))\n",
    "print((tickerchunks[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stopped at EOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leftovers = [u'EOG', u'EQT', u'EFX', u'EQIX', u'EQR', u'ESS', u'EL', u'ES', u'RE', u'EXC', u'EXPE', u'EXPD', u'ESRX', u'EXR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'EOG', u'EQT', u'EFX', u'EQIX', u'EQR', u'ESS', u'EL', u'ES', u'RE', u'EXC', u'EXPE', u'EXPD', u'ESRX', u'EXR']\n"
     ]
    }
   ],
   "source": [
    "print leftovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "[u'PGR', u'PLD', u'PRU', u'PEG', u'PSA', u'PHM', u'PVH', u'QRVO', u'PWR', u'QCOM', u'DGX', u'Q', u'RRC', u'RJF', u'RTN', u'O', u'RHT', u'REG', u'REGN', u'RF', u'RSG', u'RMD', u'RHI', u'ROK', u'COL', u'ROP', u'ROST', u'RCL', u'CRM', u'SBAC', u'SCG', u'SLB', u'SNI', u'STX', u'SEE', u'SRE', u'SHW', u'SIG', u'SPG', u'SWKS', u'SLG', u'SNA', u'SO', u'LUV', u'SPGI', u'SWK', u'SBUX', u'STT', u'SRCL', u'SYK', u'STI', u'SYMC', u'SYF', u'SNPS', u'SYY', u'TROW', u'TGT', u'TEL', u'FTI', u'TXN', u'TXT', u'TMO', u'TIF', u'TWX', u'TJX', u'TMK', u'TSS', u'TSCO', u'TDG', u'TRV', u'TRIP', u'FOXA', u'FOX', u'TSN', u'UDR', u'ULTA', u'USB', u'UA', u'UAA', u'UNP', u'UAL', u'UNH', u'UPS', u'URI', u'UTX', u'UHS', u'UNM', u'VFC', u'VLO', u'VAR', u'VTR', u'VRSN', u'VRSK', u'VZ', u'VRTX']\n"
     ]
    }
   ],
   "source": [
    "print(len(tickerchunks[4]))\n",
    "print((tickerchunks[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fy_url1 = \"http://financials.morningstar.com/ajax/ReportProcess4CSV.html?t=\"\n",
    "fy_url2= \"&reportType=is&period=12&dataType=A&order=asc&columnYear=5&number=3\"\n",
    "months =[\"january\", \"february\", \"march\", \"april\", \"may\", \"june\", \"july\", \"august\", \"september\", \"october\", \"november\", \"december\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib\n",
    "import time\n",
    "def get_fiscal_year_end():\n",
    "    loopCount = 0\n",
    "    with open(\"fy.csv\", \"w\") as fw:\n",
    "        for company in companyList:\n",
    "            print(\"working on {}\".format(company))\n",
    "            fy_url = fy_url1+company+fy_url2\n",
    "            f = urllib.urlopen(fy_url)\n",
    "            time.sleep(1)\n",
    "            myfile = f.read()\n",
    "            for line in myfile:\n",
    "                month = re.search(\"Fiscal year ends in (.*)\", myfile)\n",
    "                month = str(month.groups()).split(\".\")[0]\n",
    "                month = re.sub(r\"^\\W+\", \"\", month)\n",
    "                month = month.lower()\n",
    "            print(\"writing\")\n",
    "            fw.write(\"{},FY,{}\\n\".format(company, month))\n",
    "            fw.write(\"{},Q1,{}\\n\".format(company, months[months.index(month) - 9]))\n",
    "            fw.write(\"{},Q2,{}\\n\".format(company, months[months.index(month) - 6]))\n",
    "            fw.write(\"{},Q3,{}\\n\".format(company, months[months.index(month) - 3]))\n",
    "            fw.write(\"{},Q4,{}\\n\".format(company, month))\n",
    "            loopCount += 1\n",
    "\n",
    "            if loopCount > 529:\n",
    "                return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#get_fiscal_year_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def new_intrinio_get_company_financials(symbol, year, quarter):\n",
    "        # Get the latest FY Income Statement for \"symbol\"\n",
    "        # 'type': 'FY'\n",
    "        cleanedupdata = {}\n",
    "        base_url = \"https://api.intrinio.com\"\n",
    "        request_url = base_url + \"/financials/standardized\"\n",
    "        query_params = {\n",
    "                'ticker': symbol,\n",
    "                'statement': 'income_statement',\n",
    "                'fiscal_year' : str(year),\n",
    "                'fiscal_period' : quarter\n",
    "        }\n",
    "\n",
    "        response = requests.get(request_url, params=query_params, auth=(INTRINIO_USERNAME, INTRINIO_PASSWORD))\n",
    "        if response.status_code == 401: print(\"Unauthorized! Check your username and password.\"); exit()\n",
    "\n",
    "        if response.status_code == 429:\n",
    "            print(\"API query limit reached\")\n",
    "            return\n",
    "        data = response.json()['data']\n",
    "\n",
    "\n",
    "        for row in data:\n",
    "                tag = row['tag']\n",
    "                value = row['value']\n",
    "                cleanedupdata[\"AASYMBOL\"] = symbol\n",
    "                cleanedupdata[\"ABYEAR\"] = year\n",
    "                cleanedupdata[\"ACPeriod\"] = quarter\n",
    "                cleanedupdata[tag] = value\n",
    "\n",
    "        datalist=[]\n",
    "        for key, value in sorted(cleanedupdata.items()):\n",
    "            datalist.append(str(value))\n",
    "        \n",
    "\n",
    "        return(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def updated_cleanupdata(cleanedupdata):\n",
    "    newData = {}\n",
    "    newData['AASYMBOL'] = cleanedupdata['AASYMBOL']\n",
    "    newData['ABYEAR'] = cleanedupdata['ABYEAR']\n",
    "    newData['ACPeriod'] = cleanedupdata['ACPeriod']\n",
    "    newData['basicdilutedeps'] = cleanedupdata.get('basicdilutedeps', 0.0)\n",
    "    newData['basiceps'] = cleanedupdata.get('basiceps', 0.0)\n",
    "    #print(\"basiceps is {}\".format(newData['basiceps']))\n",
    "    \n",
    "    newData['cashdividendspershare'] = cleanedupdata.get('cashdividendspershare', 0.0)\n",
    "    newData['dilutedeps'] = cleanedupdata.get('dilutedeps', 0.0)\n",
    "    newData['incometaxexpense'] = cleanedupdata.get('incometaxexpense', 0.0)\n",
    "    newData['netincome'] = cleanedupdata.get('netincome', 0.0)\n",
    "    #print(\"netincome is {}\".format(newData['netincome']))\n",
    "    newData['netincomecontinuing'] = cleanedupdata.get('netincomecontinuing', 0.0)\n",
    "    \n",
    "    newData['netincomediscontinued'] = cleanedupdata.get('netincomediscontinued', 0.0)\n",
    "    newData['netincometocommon'] = cleanedupdata.get('netincometocommon', 0.0)\n",
    "    newData['netincometononcontrollinginterest'] = cleanedupdata.get('netincometononcontrollinginterest', 0.0)\n",
    "    newData['operatingcostofrevenue'] = cleanedupdata.get('operatingcostofrevenue', 0.0)\n",
    "    newData['operatingrevenue'] = cleanedupdata.get('operatingrevenue', 0.0)\n",
    "    #print(\"operatingrevenue is {}\".format(newData['operatingrevenue']))\n",
    "    \n",
    "    newData['othercostofrevenue'] = cleanedupdata.get('othercostofrevenue', 0.0)\n",
    "    newData['otherincome'] = cleanedupdata.get('otherincome', 0.0)\n",
    "    newData['preferreddividends'] = cleanedupdata.get('preferreddividends', 0.0)\n",
    "    newData['sgaexpense'] = cleanedupdata.get('sgaexpense', 0.0)\n",
    "    newData['totalcostofrevenue'] = cleanedupdata.get('totalcostofrevenue', 0.0)\n",
    "    \n",
    "    newData['totalgrossprofit'] = cleanedupdata.get('totalgrossprofit', 0.0)\n",
    "    #print(\"totalgrossprofit is {}\".format(newData['totalgrossprofit']))\n",
    "    newData['totalinterestexpense'] = cleanedupdata.get('totalinterestexpense', 0.0)\n",
    "    newData['totaloperatingexpenses'] = cleanedupdata.get('totaloperatingexpenses', 0.0)\n",
    "    newData['totaloperatingincome'] = cleanedupdata.get('totaloperatingincome', 0.0)\n",
    "    newData['totalotherincome'] = cleanedupdata.get('totalotherincome', 0.0)\n",
    "    \n",
    "    newData['totalpretaxincome'] = cleanedupdata.get('totalpretaxincome', 0.0)\n",
    "    newData['totalrevenue'] = cleanedupdata.get('totalrevenue', 0.0)\n",
    "    #print(\"totalrevenue is {}\".format(newData['totalrevenue']))\n",
    "    newData['weightedavebasicdilutedsharesos'] = cleanedupdata.get('weightedavebasicdilutedsharesos', 0.0)\n",
    "    newData['weightedavebasicsharesos'] = cleanedupdata.get('weightedavebasicsharesos', 0.0)\n",
    "    newData['weightedavedilutedsharesos'] = cleanedupdata.get('weightedavedilutedsharesos', 0.0)\n",
    "    \n",
    "    #newData[] = cleanedupdata.get(, 0.0)\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "ticker,year,quarter,basicdilutedeps,basiceps,cashdividendspershare,dilutedeps,incometaxexpense,netincome,netincomecontinuing,netincomediscontinued,netincometocommon,netincometononcontrollinginterest,operatingcostofrevenue,operatingrevenue,othercostofrevenue,otherincome,preferreddividends,sgaexpense,totalcostofrevenue,totalgrossprofit,totalinterestexpense,totaloperatingexpenses,totaloperatingincome,totalotherincome,totalpretaxincome,totalrevenue,weightedavebasicdilutedsharesos,weightedavebasicsharesos,weightedavedilutedsharesos\n"
     ]
    }
   ],
   "source": [
    "attributes = [\"ticker\", \"year\", \"quarter\", \"basicdilutedeps\", \"basiceps\",\n",
    "              'cashdividendspershare', 'dilutedeps', 'incometaxexpense', 'netincome', 'netincomecontinuing',\n",
    "              'netincomediscontinued', 'netincometocommon', 'netincometononcontrollinginterest',  \n",
    "                  'operatingcostofrevenue', 'operatingrevenue',\n",
    "              'othercostofrevenue', 'otherincome', 'preferreddividends', 'sgaexpense', 'totalcostofrevenue',\n",
    "              'totalgrossprofit', 'totalinterestexpense', 'totaloperatingexpenses', 'totaloperatingincome', 'totalotherincome', \n",
    "              'totalpretaxincome', 'totalrevenue', 'weightedavebasicdilutedsharesos', 'weightedavebasicsharesos', 'weightedavedilutedsharesos'\n",
    "                 ]\n",
    "print(len(attributes))\n",
    "\n",
    "xx = \",\".join(attributes)\n",
    "print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def updated_intrinio_get_company_financials(symbol, year, quarter):\n",
    "        # Get the latest FY Income Statement for \"symbol\"\n",
    "        # 'type': 'FY'\n",
    "        cleanedupdata = {}\n",
    "        base_url = \"https://api.intrinio.com\"\n",
    "        request_url = base_url + \"/financials/standardized\"\n",
    "        query_params = {\n",
    "                'ticker': symbol,\n",
    "                'statement': 'income_statement',\n",
    "                'fiscal_year' : str(year),\n",
    "                'fiscal_period' : quarter\n",
    "        }\n",
    "\n",
    "        response = requests.get(request_url, params=query_params, auth=(INTRINIO_USERNAME, INTRINIO_PASSWORD))\n",
    "        if response.status_code == 401: print(\"Unauthorized! Check your username and password.\"); exit()\n",
    "\n",
    "        if response.status_code == 429:\n",
    "            print(\"API query limit reached\")\n",
    "            return\n",
    "        data = response.json()['data']\n",
    "\n",
    "        #print(data['basicdilutedeps'])\n",
    "        for row in data:\n",
    "                #print(row)\n",
    "                tag = row['tag']\n",
    "                value = row['value']\n",
    "\n",
    "                cleanedupdata[tag] = value\n",
    "\n",
    "        datalist=[]\n",
    "        attr = []\n",
    "        cleanedupdata[\"AASYMBOL\"] = symbol\n",
    "        cleanedupdata[\"ABYEAR\"] = year\n",
    "        cleanedupdata[\"ACPeriod\"] = quarter\n",
    "        cleanedupdata = updated_cleanupdata(cleanedupdata)\n",
    "        for key, value in sorted(cleanedupdata.items()):\n",
    "            datalist.append(str(value))\n",
    "            attr.append(str(key))\n",
    " \n",
    "        return(datalist, attr)\n",
    "data = updated_intrinio_get_company_financials('GE', '2008', 'Q1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/NatarajanShankar/UC_Berkeley/Final_term/Capstone/W210/MIDS_capstone/metadata\n",
      "/Users/NatarajanShankar/UC_Berkeley/Final_term/Capstone/W210/MIDS_capstone/data/nlp_by_company\n",
      "['COL.csv', 'CRM.csv', 'DGX.csv', 'FOX.csv', 'FOXA.csv', 'FTI.csv', 'JWN.csv', 'KORS.csv', 'LUV.csv', 'M.csv', 'MA.csv', 'MAA.csv', 'MAC.csv', 'MAR.csv', 'MAS.csv', 'MAT.csv', 'MCD.csv', 'MCHP.csv', 'MCK.csv', 'MCO.csv', 'MDLZ.csv', 'MDT.csv', 'MET.csv', 'MGM.csv', 'MHK.csv', 'MKC.csv', 'MLM.csv', 'MMC.csv', 'MNST.csv', 'MON.csv', 'MOS.csv', 'MPC.csv', 'MRK.csv', 'MRO.csv', 'MS.csv', 'MSFT.csv', 'MSI.csv', 'MTD.csv', 'MU.csv', 'MYL.csv', 'NAVI.csv', 'NDAQ.csv', 'NEE.csv', 'NEM.csv', 'NFLX.csv', 'NFX.csv', 'NI.csv', 'NKE.csv', 'NLSN.csv', 'NOC.csv', 'NOV.csv', 'NRG.csv', 'NSC.csv', 'NTAP.csv', 'NTRS.csv', 'NUE.csv', 'NVDA.csv', 'NWS.csv', 'NWSA.csv', 'O.csv', 'OKE.csv', 'OMC.csv', 'ORCL.csv', 'ORLY.csv', 'OXY.csv', 'PAYX.csv', 'PBCT.csv', 'PCAR.csv', 'PCG.csv', 'PCLN.csv', 'PDCO.csv', 'PEG.csv', 'PEP.csv', 'PFE.csv', 'PFG.csv', 'PG.csv', 'PGR.csv', 'PH.csv', 'PHM.csv', 'PKG.csv', 'PKI.csv', 'PLD.csv', 'PM.csv', 'PNC.csv', 'PNR.csv', 'PNW.csv', 'PPG.csv', 'PPL.csv', 'PRGO.csv', 'PRU.csv', 'PSA.csv', 'PSX.csv', 'PVH.csv', 'PWR.csv', 'PX.csv', 'PXD.csv', 'PYPL.csv', 'Q.csv', 'QCOM.csv', 'QRVO.csv', 'RCL.csv', 'REG.csv', 'REGN.csv', 'RF.csv', 'RHI.csv', 'RHT.csv', 'RJF.csv', 'RL.csv', 'RMD.csv', 'ROK.csv', 'ROP.csv', 'ROST.csv', 'RRC.csv', 'RSG.csv', 'RTN.csv', 'SBAC.csv', 'SBUX.csv', 'SCG.csv', 'SEE.csv', 'SHW.csv', 'SIG.csv', 'SLB.csv', 'SLG.csv', 'SNA.csv', 'SNI.csv', 'SNPS.csv', 'SO.csv', 'SPG.csv', 'SPGI.csv', 'SRCL.csv', 'SRE.csv', 'STI.csv', 'STT.csv', 'STX.csv', 'SWK.csv', 'SWKS.csv', 'SYF.csv', 'SYK.csv', 'SYMC.csv', 'SYY.csv', 'TAP.csv', 'TDG.csv', 'TEL.csv', 'TGT.csv', 'TIF.csv', 'TJX.csv', 'TMK.csv', 'TMO.csv', 'TRIP.csv', 'TROW.csv', 'TRV.csv', 'TSCO.csv', 'TSN.csv', 'TSS.csv', 'TWX.csv', 'TXN.csv', 'TXT.csv', 'UDR.csv', 'ULTA.csv', 'USB.csv']\n",
      "['COL', 'CRM', 'DGX', 'FOX', 'FOXA', 'FTI', 'JWN', 'KORS', 'LUV', 'M', 'MA', 'MAA', 'MAC', 'MAR', 'MAS', 'MAT', 'MCD', 'MCHP', 'MCK', 'MCO', 'MDLZ', 'MDT', 'MET', 'MGM', 'MHK', 'MKC', 'MLM', 'MMC', 'MNST', 'MON', 'MOS', 'MPC', 'MRK', 'MRO', 'MS', 'MSFT', 'MSI', 'MTD', 'MU', 'MYL', 'NAVI', 'NDAQ', 'NEE', 'NEM', 'NFLX', 'NFX', 'NI', 'NKE', 'NLSN', 'NOC', 'NOV', 'NRG', 'NSC', 'NTAP', 'NTRS', 'NUE', 'NVDA', 'NWS', 'NWSA', 'O', 'OKE', 'OMC', 'ORCL', 'ORLY', 'OXY', 'PAYX', 'PBCT', 'PCAR', 'PCG', 'PCLN', 'PDCO', 'PEG', 'PEP', 'PFE', 'PFG', 'PG', 'PGR', 'PH', 'PHM', 'PKG', 'PKI', 'PLD', 'PM', 'PNC', 'PNR', 'PNW', 'PPG', 'PPL', 'PRGO', 'PRU', 'PSA', 'PSX', 'PVH', 'PWR', 'PX', 'PXD', 'PYPL', 'Q', 'QCOM', 'QRVO', 'RCL', 'REG', 'REGN', 'RF', 'RHI', 'RHT', 'RJF', 'RL', 'RMD', 'ROK', 'ROP', 'ROST', 'RRC', 'RSG', 'RTN', 'SBAC', 'SBUX', 'SCG', 'SEE', 'SHW', 'SIG', 'SLB', 'SLG', 'SNA', 'SNI', 'SNPS', 'SO', 'SPG', 'SPGI', 'SRCL', 'SRE', 'STI', 'STT', 'STX', 'SWK', 'SWKS', 'SYF', 'SYK', 'SYMC', 'SYY', 'TAP', 'TDG', 'TEL', 'TGT', 'TIF', 'TJX', 'TMK', 'TMO', 'TRIP', 'TROW', 'TRV', 'TSCO', 'TSN', 'TSS', 'TWX', 'TXN', 'TXT', 'UDR', 'ULTA', 'USB']\n",
      "/Users/NatarajanShankar/UC_Berkeley/Final_term/Capstone/W210/MIDS_capstone/metadata\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "%cd ../data/nlp_by_company\n",
    "import glob\n",
    "xx = list(glob.glob(\"*.csv\"))\n",
    "print(xx)\n",
    "yy = []\n",
    "\n",
    "for item in xx:\n",
    "    yy.append(str(item).strip('.csv'))\n",
    "\n",
    "print(yy)\n",
    "%cd ../../metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    }
   ],
   "source": [
    "company = ['COL', 'CRM', 'DGX', 'FOX', 'FOXA', 'FTI', 'JWN', 'KORS', 'LUV', 'M', 'MA', 'MAA', \n",
    "               'MAC', 'MAR', 'MAS', 'MAT', 'MCD', 'MCHP', 'MCK', 'MCO', 'MDLZ', 'MDT', 'MET', 'MGM', \n",
    "               'MHK', 'MKC', 'MLM', 'MMC', 'MNST', 'MON', 'MOS', 'MPC', 'MRK', 'MRO', 'MS', 'MSFT', \n",
    "               'MSI', 'MTD', 'MU', 'MYL', 'NAVI', 'NDAQ', 'NEE', 'NEM', 'NFLX', 'NFX', 'NI', 'NKE', \n",
    "               'NLSN', 'NOC', 'NOV', 'NRG', 'NSC', 'NTAP', 'NTRS', 'NUE', 'NVDA', 'NWS', 'NWSA', 'O', \n",
    "               'OKE', 'OMC', 'ORCL', 'ORLY', 'OXY', 'PAYX', 'PBCT', 'PCAR', 'PCG', 'PCLN', 'PDCO', \n",
    "               'PEG', 'PEP', 'PFE', 'PFG', 'PG', 'PGR', 'PH', 'PHM', 'PKG', 'PKI', 'PLD', 'PM', 'PNC', \n",
    "               'PNR', 'PNW', 'PPG', 'PPL', 'PRGO', 'PRU', 'PSA', 'PSX', 'PVH', 'PWR', 'PX', 'PXD', \n",
    "               'PYPL', 'Q', 'QCOM', 'QRVO', 'RCL', 'REG', 'REGN', 'RF', 'RHI', 'RHT', 'RJF', 'RL', \n",
    "               'RMD', 'ROK', 'ROP', 'ROST', 'RRC', 'RSG', 'RTN', 'SBAC', 'SBUX', 'SCG', 'SEE', 'SHW', \n",
    "               'SIG', 'SLB', 'SLG', 'SNA', 'SNI', 'SNPS', 'SO', 'SPG', 'SPGI', 'SRCL', 'SRE', 'STI', \n",
    "               'STT', 'STX', 'SWK', 'SWKS', 'SYF', 'SYK', 'SYMC', 'SYY', 'TAP', 'TDG', 'TEL', 'TGT', \n",
    "               'TIF', 'TJX', 'TMK', 'TMO', 'TRIP', 'TROW', 'TRV', 'TSCO', 'TSN', 'TSS', 'TWX', 'TXN', \n",
    "               'TXT', 'UDR', 'ULTA', 'USB']\n",
    "\n",
    "print(len(company))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_financial_data():\n",
    "    SandP500 = {}\n",
    "    companyList = []\n",
    "    with open(\"SandP500_symbols.txt\", \"r\") as fr:\n",
    "            for line in fr:\n",
    "                    company = json.loads(line)\n",
    "                    SandP500[company[\"symbol\"]] = line\n",
    "                    companyList.append(company[\"symbol\"])\n",
    "\n",
    "    tickerchunks = [companyList[x:x+95] for x in xrange(0, len(companyList), 95)]\n",
    "\n",
    "\n",
    "    nlp_companies = ['COL', 'CRM', 'DGX', 'FOX', 'FOXA', 'FTI', 'JWN', 'KORS', 'LUV', 'M', 'MA', 'MAA', \n",
    "               'MAC', 'MAR', 'MAS', 'MAT', 'MCD', 'MCHP', 'MCK', 'MCO', 'MDLZ', 'MDT', 'MET', 'MGM', \n",
    "               'MHK', 'MKC', 'MLM', 'MMC', 'MNST', 'MON', 'MOS', 'MPC', 'MRK', 'MRO', 'MS', 'MSFT', \n",
    "               'MSI', 'MTD', 'MU', 'MYL', 'NAVI', 'NDAQ', 'NEE', 'NEM', 'NFLX', 'NFX', 'NI', 'NKE', \n",
    "               'NLSN', 'NOC', 'NOV', 'NRG', 'NSC', 'NTAP', 'NTRS', 'NUE', 'NVDA', 'NWS', 'NWSA', 'O', \n",
    "               'OKE', 'OMC', 'ORCL', 'ORLY', 'OXY', 'PAYX', 'PBCT', 'PCAR', 'PCG', 'PCLN', 'PDCO', \n",
    "               'PEG', 'PEP', 'PFE', 'PFG', 'PG', 'PGR', 'PH', 'PHM', 'PKG', 'PKI', 'PLD', 'PM', 'PNC', \n",
    "               'PNR', 'PNW', 'PPG', 'PPL', 'PRGO', 'PRU', 'PSA', 'PSX', 'PVH', 'PWR', 'PX', 'PXD', \n",
    "               'PYPL', 'Q', 'QCOM', 'QRVO', 'RCL', 'REG', 'REGN', 'RF', 'RHI', 'RHT', 'RJF', 'RL', \n",
    "               'RMD', 'ROK', 'ROP', 'ROST', 'RRC', 'RSG', 'RTN', 'SBAC', 'SBUX', 'SCG', 'SEE', 'SHW', \n",
    "               'SIG', 'SLB', 'SLG', 'SNA', 'SNI', 'SNPS', 'SO', 'SPG', 'SPGI', 'SRCL', 'SRE', 'STI', \n",
    "               'STT', 'STX', 'SWK', 'SWKS', 'SYF', 'SYK', 'SYMC', 'SYY', 'TAP', 'TDG', 'TEL', 'TGT', \n",
    "               'TIF', 'TJX', 'TMK', 'TMO', 'TRIP', 'TROW', 'TRV', 'TSCO', 'TSN', 'TSS', 'TWX', 'TXN', \n",
    "               'TXT', 'UDR', 'ULTA', 'USB']\n",
    "    years = [2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017]\n",
    "    quarters = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"FY\"]\n",
    "    #years = [2010]\n",
    "    #quarters = [\"Q1\", \"Q2\"]\n",
    "    #companies = [\"GE\", \"CSCO\", \"GOOG\", \"FACE\"]\n",
    "\n",
    "    bigDict = {}\n",
    "\n",
    "    attributes = [\"ticker\", \"year\", \"quarter\", \"basicdilutedeps\", \"basiceps\",\n",
    "              'cashdividendspershare', 'dilutedeps', 'incometaxexpense', 'netincome', 'netincomecontinuing',\n",
    "              'netincomediscontinued', 'netincometocommon', 'netincometononcontrollinginterest',  \n",
    "                  'operatingcostofrevenue', 'operatingrevenue',\n",
    "              'othercostofrevenue', 'otherincome', 'preferreddividends', 'sgaexpense', 'totalcostofrevenue',\n",
    "              'totalgrossprofit', 'totalinterestexpense', 'totaloperatingexpenses', 'totaloperatingincome', 'totalotherincome', \n",
    "              'totalpretaxincome', 'totalrevenue', 'weightedavebasicdilutedsharesos', 'weightedavebasicsharesos', 'weightedavedilutedsharesos'\n",
    "                 ]\n",
    "    \n",
    "    #specific_company = ['TXN', 'TXT', 'UDR', 'ULTA', 'USB']\n",
    "    print(len(attributes))\n",
    "\n",
    "    xx = \",\".join(attributes) + \"\\n\"\n",
    "\n",
    "    # tickerchunks[1], tickerchunks[2], tickerchunks[3] and tickerchunks[5] are done\n",
    "    # Re-doing 0 block, 3 is complete, 2 is complete, 1 is done with leftovers, 5 is complete. \n",
    "    loopIndex = 0\n",
    "    for company in leftovers:\n",
    "    #for company in tickerchunks[4]:\n",
    "    #for company in specific_company:\n",
    "    #for company in nlp_companies:\n",
    "        #with open(\"../data/nlp_by_company/revenue/\"+company+\"_Financials_by_Quarter.csv\", 'w') as fw:\n",
    "        with open(\"./revenue/\"+company+\"_Financials_by_Quarter.csv\", 'w') as fw:\n",
    "            fw.write(xx)\n",
    "            print(\"working on {} - {}\".format(company, loopIndex))\n",
    "#             if loopIndex > 2:\n",
    "#                 break\n",
    "            loopIndex += 1\n",
    "            #print(\"working on company {}\".format(company))\n",
    "            for year in years:\n",
    "\n",
    "                #print(\"working on year {}\".format(year))\n",
    "                for quarter in quarters:\n",
    "                    #print(\"working on quarter {}\".format(quarter))\n",
    "\n",
    "                    data, _ = updated_intrinio_get_company_financials(company, str(year), quarter)\n",
    "                    \n",
    "                    # Convert list to string\n",
    "                    datastring = \",\".join(data)\n",
    "                    \n",
    "                    # Add a linefeed so that every data point is on a different line\n",
    "                    datastring +=\"\\n\"\n",
    "\n",
    "                    # Write the data to the open file for this company\n",
    "                    fw.write(datastring)\n",
    "                    #break\n",
    "                #break\n",
    "            #break\n",
    "        #break\n",
    "\n",
    "            print(\"DONE with {}\".format(company))\n",
    "            #return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/NatarajanShankar/UC_Berkeley/Final_term/Capstone/W210/MIDS_capstone/metadata\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "working on EOG - 0\n",
      "DONE with EOG\n",
      "working on EQT - 1\n",
      "DONE with EQT\n",
      "working on EFX - 2\n",
      "DONE with EFX\n",
      "working on EQIX - 3\n",
      "DONE with EQIX\n",
      "working on EQR - 4\n",
      "DONE with EQR\n",
      "working on ESS - 5\n",
      "DONE with ESS\n",
      "working on EL - 6\n",
      "DONE with EL\n",
      "working on ES - 7\n",
      "DONE with ES\n",
      "working on RE - 8\n",
      "DONE with RE\n",
      "working on EXC - 9\n",
      "DONE with EXC\n",
      "working on EXPE - 10\n",
      "DONE with EXPE\n",
      "working on EXPD - 11\n",
      "DONE with EXPD\n",
      "working on ESRX - 12\n",
      "DONE with ESRX\n",
      "working on EXR - 13\n",
      "DONE with EXR\n"
     ]
    }
   ],
   "source": [
    "generate_financial_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/NatarajanShankar/UC_Berkeley/Final_term/Capstone/W210/MIDS_capstone/metadata\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/NatarajanShankar/UC_Berkeley/Final_term/Capstone/W210/MIDS_capstone/metadata\")\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import ast\n",
    "\n",
    "def convert_json_to_csv():\n",
    "    companyDict = {}\n",
    "    os.chdir(\"./data\")\n",
    "    #print(\"got here\")\n",
    "    for datafile in glob.glob(\"*Financials*.json\"):\n",
    "        #print(datafile)\n",
    "        with open(datafile, \"r\") as fr:\n",
    "            #print (\"Processing {}\".format(datafile))\n",
    "            for line in fr:\n",
    "                companyDict = ast.literal_eval(line)\n",
    "                \n",
    "                # Save company ticker\n",
    "                for company, companyvalue in companyDict.items():\n",
    "                    #print(\"Company is\")\n",
    "                    #print(\"{}\".format(company, end=''))\n",
    "                    # For every year subset\n",
    "                    if isinstance(companyvalue, dict):\n",
    "                        for year, yearvalue in companyvalue.items():\n",
    "                            #print(\"Year is\")\n",
    "                            #print(\"{}\".format(year, end=''))\n",
    "                            # Look at the corresponding quarter\n",
    "                            if isinstance(yearvalue, dict):\n",
    "                                datalist=[]\n",
    "                                # Look at company quarter\n",
    "                                for quarter, quartervalue in yearvalue.items():\n",
    "                                    #print(\"Quarter is\")\n",
    "                                    #print(\"{}\".format(quarter, end=''))\n",
    "                                    for financialdata in quartervalue.values():\n",
    "                                        datalist.append(financialdata)\n",
    "                                    \n",
    "                                    if len(datalist) > 21:\n",
    "                                        datalist[14] = \"IGNORE\"\n",
    "                                        datalist[21] = \"IGNORE\"\n",
    "                                    \n",
    "                                    if len(datalist) == 2:\n",
    "                                        datalist[0] = \"\"\n",
    "                                        datalist[1] = \"\"\n",
    "                                    print(\"{},{},{},{}\".format(company, year, quarter, \",\".join(datalist), end=''))\n",
    "                                    \n",
    "                                    datalist = []\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLIR,2010,Q1,\n",
      "FLIR,2010,Q4,\n"
     ]
    }
   ],
   "source": [
    "convert_json_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_company_financial_data_all(symbol):\n",
    "    companyDict = {}\n",
    "    with open(\"./data/Financials.json\", \"r\") as fp:\n",
    "        #companyDict = json.load(fp)\n",
    "        for line in fp:\n",
    "            companyDict = ast.literal_eval(line)\n",
    "\n",
    "        for ticker in companyDict.keys():\n",
    "            if ticker == symbol:\n",
    "                print symbol, companyDict[symbol]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_company_financial_data_all(\"GE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_company_financial_data_by_year(symbol, year):\n",
    "    companyDict = {}\n",
    "    with open(\"./data/Financials.json\", \"r\") as fp:\n",
    "        #companyDict = json.load(fp)\n",
    "        for line in fp:\n",
    "            companyDict = ast.literal_eval(line)\n",
    "\n",
    "        for ticker in companyDict.keys():\n",
    "            if ticker == symbol:\n",
    "                print symbol, companyDict[symbol][year]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_company_financial_data_by_year(\"GE\", \"2014\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_company_financial_data_by_year_and_attr(symbol, year, attribute):\n",
    "    companyDict = {}\n",
    "    with open(\"./data/Financials.json\", \"r\") as fp:\n",
    "        #companyDict = json.load(fp)\n",
    "        for line in fp:\n",
    "            companyDict = ast.literal_eval(line)\n",
    "\n",
    "        for ticker in companyDict.keys():\n",
    "            if ticker == symbol:\n",
    "                print symbol, companyDict[symbol][year][attribute]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_company_financial_data_by_year_and_attr(\"GE\", \"2014\", \"basiceps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_company_financial_data_csv(symbol):\n",
    "    companyDict = {}\n",
    "    with open(\"./data/Financials.json\", \"r\") as fp:\n",
    "        for line in fp:\n",
    "            companyDict = ast.literal_eval(line)\n",
    "            \n",
    "        for ticker in companyDict.keys():\n",
    "            if ticker == symbol:\n",
    "                print symbol, companyDict\n",
    "            \n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
