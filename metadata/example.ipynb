{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/NatarajanShankar/UC_Berkeley/Final_term/Capstone/W210/MIDS_capstone/metadata\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from api_key import INTRINIO_USERNAME\n",
    "from api_key import INTRINIO_PASSWORD             \n",
    "\n",
    "import md_intrinio_client\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from md_intrinio_client import intrinio_get_company_metadata\n",
    "from md_intrinio_client import intrinio_get_company_financials\n",
    "from md_intrinio_client import intrinio_get_company_financials_csv\n",
    "from md_intrinio_client import get_SandP_metadata\n",
    "from md_intrinio_client import test_SandP_metadata\n",
    "\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import finsymbols\n",
    "import ast\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/NatarajanShankar/UC_Berkeley/Final_term/Capstone/W210/MIDS_capstone/metadata\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('/home/skillachie/Desktop/')\n",
    "from finsymbols import symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json \n",
    "SandP500 = {}\n",
    "companyList = []\n",
    "with open(\"SandP500_symbols.txt\", \"r\") as fr:\n",
    "            for line in fr:\n",
    "                    company = json.loads(line)\n",
    "                    SandP500[company[\"symbol\"]] = line\n",
    "                    companyList.append(company[\"symbol\"])\n",
    "\n",
    "tickerchunks = [companyList[x:x+100] for x in xrange(0, len(companyList), 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[u'MMC', u'MLM', u'MAS', u'MA', u'MAT', u'MKC', u'MCD', u'MCK', u'MDT', u'MRK', u'MET', u'MTD', u'MGM', u'KORS', u'MCHP', u'MU', u'MSFT', u'MAA', u'MHK', u'TAP', u'MDLZ', u'MON', u'MNST', u'MCO', u'MS', u'MOS', u'MSI', u'MYL', u'NDAQ', u'NOV', u'NAVI', u'NTAP', u'NFLX', u'NWL', u'NFX', u'NEM', u'NWSA', u'NWS', u'NEE', u'NLSN', u'NKE', u'NI', u'NBL', u'JWN', u'NSC', u'NTRS', u'NOC', u'NRG', u'NUE', u'NVDA', u'ORLY', u'OXY', u'OMC', u'OKE', u'ORCL', u'PCAR', u'PKG', u'PH', u'PDCO', u'PAYX', u'PYPL', u'PNR', u'PBCT', u'PEP', u'PKI', u'PRGO', u'PFE', u'PCG', u'PM', u'PSX', u'PNW', u'PXD', u'PNC', u'RL', u'PPG', u'PPL', u'PX', u'PCLN', u'PFG', u'PG', u'PGR', u'PLD', u'PRU', u'PEG', u'PSA', u'PHM', u'PVH', u'QRVO', u'PWR', u'QCOM', u'DGX', u'Q', u'RRC', u'RJF', u'RTN', u'O', u'RHT', u'REG', u'REGN', u'RF']\n"
     ]
    }
   ],
   "source": [
    "print(len(tickerchunks[3]))\n",
    "print((tickerchunks[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def generate_financial_data():\n",
    "#     SandP500 = {}\n",
    "#     companyList = []\n",
    "#     with open(\"SandP500_symbols.txt\", \"r\") as fr:\n",
    "#             for line in fr:\n",
    "#                     company = json.loads(line)\n",
    "#                     SandP500[company[\"symbol\"]] = line\n",
    "#                     companyList.append(company[\"symbol\"])\n",
    "\n",
    "#     tickerchunks = [companyList[x:x+100] for x in xrange(0, len(companyList), 100)]\n",
    "\n",
    "#     #print(\"Testing company financials api via CSV\")\n",
    "\n",
    "#     #years = [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017]\n",
    "#     #quarters = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"FY\"]\n",
    "#     years = [2010]\n",
    "#     quarters = [\"Q1\", \"Q4\"]\n",
    "#     #companies = [\"GE\", \"CSCO\", \"GOOG\", \"FACE\"]\n",
    "\n",
    "#     bigDict = {}\n",
    "\n",
    "#     loopindex = 0\n",
    "#     for company in tickerchunks[2]:\n",
    "#         print(\"working on {}\".format(company))\n",
    "#         if loopindex > 2:\n",
    "#             break\n",
    "#         loopindex += 1\n",
    "#         bigDict[company] = {}\n",
    "#         #print(\"working on company {}\".format(company))\n",
    "#         for year in years:\n",
    "#             bigDict[company][year] = {}\n",
    "#             print(\"working on year {}\".format(year))\n",
    "#             for quarter in quarters:\n",
    "#                 print(\"working on quarter {}\".format(quarter))\n",
    "#                 bigDict[company][year][quarter] = {}\n",
    "#                 data = intrinio_get_company_financials_csv(company, str(year), quarter)\n",
    "#                 print(data)\n",
    "#                 financials = list(data)\n",
    "\n",
    "#                 print(\"FINANCIALS\")\n",
    "#                 print (financials)\n",
    "#                 breakdown = ''.join(financials)\n",
    "#                 #print(breakdown)\n",
    "#                 newdata = breakdown.split(\"\\n\")\n",
    "#                 print(newdata)\n",
    "#                 for item in newdata:\n",
    "#                     splititem = item.split(\",\")\n",
    "#                     if len(splititem) < 2:\n",
    "#                         continue\n",
    "#                     bigDict[company][year][quarter][splititem[0]]=  {}\n",
    "#                     bigDict[company][year][quarter][splititem[0]]= splititem[1]\n",
    "#         print(\"DONE with {}\".format(company))      \n",
    "        \n",
    "        \n",
    "#         print(\"Done with {}\".format(company))\n",
    "#         with open(\"./data/\"+company+\"_Financials_by_Quarter.json\", 'w') as fp:\n",
    "#             fp.write(json.dumps(bigDict))\n",
    "#             print(\"{}\".format(\"./data/\"+company+\"_Financials_by_Quarter.json\"))\n",
    "#             bigDict = {}\n",
    "#         return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_intrinio_get_company_financials(symbol, year, quarter):\n",
    "        # Get the latest FY Income Statement for \"symbol\"\n",
    "        # 'type': 'FY'\n",
    "        cleanedupdata = {}\n",
    "        base_url = \"https://api.intrinio.com\"\n",
    "        request_url = base_url + \"/financials/standardized\"\n",
    "        query_params = {\n",
    "                'ticker': symbol,\n",
    "                'statement': 'income_statement',\n",
    "                'fiscal_year' : str(year),\n",
    "                'fiscal_period' : quarter\n",
    "        }\n",
    "\n",
    "        response = requests.get(request_url, params=query_params, auth=(INTRINIO_USERNAME, INTRINIO_PASSWORD))\n",
    "        if response.status_code == 401: print(\"Unauthorized! Check your username and password.\"); exit()\n",
    "\n",
    "        if response.status_code == 429:\n",
    "            print(\"API query limit reached\")\n",
    "            return\n",
    "        data = response.json()['data']\n",
    "\n",
    "        #print(data['basicdilutedeps'])\n",
    "        for row in data:\n",
    "                tag = row['tag']\n",
    "                value = row['value']\n",
    "                cleanedupdata[\"AASYMBOL\"] = symbol\n",
    "                cleanedupdata[\"ABYEAR\"] = year\n",
    "                cleanedupdata[\"ACPeriod\"] = quarter\n",
    "                cleanedupdata[tag] = value\n",
    "                #print(tag + \": \" + str(value))\n",
    "#         for k, v in xx.items():\n",
    "#             print(k, v)\n",
    "        datalist=[]\n",
    "        for key, value in sorted(cleanedupdata.items()):\n",
    "            datalist.append(str(value))\n",
    "        \n",
    "        #print(json.dumps(cleanedupdata, indent=1, sort_keys=True))\n",
    "        #print(datalist)\n",
    "        #print(\"{}\".format(\"\".join(datalist)))\n",
    "        #return(\",\".join(datalist))\n",
    "        return(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updated_cleanupdata(cleanedupdata):\n",
    "    newData = {}\n",
    "    newData['AASYMBOL'] = cleanedupdata['AASYMBOL']\n",
    "    newData['ABYEAR'] = cleanedupdata['ABYEAR']\n",
    "    newData['ACPeriod'] = cleanedupdata['ACPeriod']\n",
    "    newData['basicdilutedeps'] = cleanedupdata.get('basicdilutedeps', 0.0)\n",
    "    newData['basiceps'] = cleanedupdata.get('basiceps', 0.0)\n",
    "    \n",
    "    newData['cashdividendspershare'] = cleanedupdata.get('cashdividendspershare', 0.0)\n",
    "    newData['dilutedeps'] = cleanedupdata.get('dilutedeps', 0.0)\n",
    "    newData['incometaxexpense'] = cleanedupdata.get('incometaxexpense', 0.0)\n",
    "    newData['netincome'] = cleanedupdata.get('netincome', 0.0)\n",
    "    newData['netincomecontinuing'] = cleanedupdata.get('netincomecontinuing', 0.0)\n",
    "    \n",
    "    newData['netincomediscontinued'] = cleanedupdata.get('netincomediscontinued', 0.0)\n",
    "    newData['netincometocommon'] = cleanedupdata.get('netincometocommon', 0.0)\n",
    "    newData['netincometononcontrollinginterest'] = cleanedupdata.get('netincometononcontrollinginterest', 0.0)\n",
    "    newData['operatingcostofrevenue'] = cleanedupdata.get('operatingcostofrevenue', 0.0)\n",
    "    newData['operatingrevenue'] = cleanedupdata.get('operatingrevenue', 0.0)\n",
    "    \n",
    "    newData['othercostofrevenue'] = cleanedupdata.get('othercostofrevenue', 0.0)\n",
    "    newData['otherincome'] = cleanedupdata.get('otherincome', 0.0)\n",
    "    newData['preferreddividends'] = cleanedupdata.get('preferreddividends', 0.0)\n",
    "    newData['sgaexpense'] = cleanedupdata.get('sgaexpense', 0.0)\n",
    "    newData['totalcostofrevenue'] = cleanedupdata.get('totalcostofrevenue', 0.0)\n",
    "    \n",
    "    newData['totalgrossprofit'] = cleanedupdata.get('totalgrossprofit', 0.0)\n",
    "    newData['totalinterestexpense'] = cleanedupdata.get('totalinterestexpense', 0.0)\n",
    "    newData['totaloperatingexpenses'] = cleanedupdata.get('totaloperatingexpenses', 0.0)\n",
    "    newData['totaloperatingincome'] = cleanedupdata.get('totaloperatingincome', 0.0)\n",
    "    newData['totalotherincome'] = cleanedupdata.get('totalotherincome', 0.0)\n",
    "    \n",
    "    newData['totalpretaxincome'] = cleanedupdata.get('totalpretaxincome', 0.0)\n",
    "    newData['totalrevenue'] = cleanedupdata.get('totalrevenue', 0.0)\n",
    "    newData['weightedavebasicdilutedsharesos'] = cleanedupdata.get('weightedavebasicdilutedsharesos', 0.0)\n",
    "    newData['weightedavebasicsharesos'] = cleanedupdata.get('weightedavebasicsharesos', 0.0)\n",
    "    newData['weightedavedilutedsharesos'] = cleanedupdata.get('weightedavedilutedsharesos', 0.0)\n",
    "    \n",
    "    #newData[] = cleanedupdata.get(, 0.0)\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "ticker,year,quarter,basicdilutedeps,basiceps,cashdividendspershare,dilutedeps,incometaxexpense,netincome,netincomecontinuing,netincomediscontinued,netincometocommon,netincometononcontrollinginterest,totalcostofrevenue,operatingcostofrevenue,operatingrevenue,othercostofrevenue,otherincome,preferreddividends,sgaexpense,totalgrossprofit,totalinterestexpense,totaloperatingexpenses,totaloperatingincome,totalotherincome,totalpretaxincome,totalrevenue,weightedavebasicdilutedsharesos,weightedavebasicsharesos,weightedavedilutedsharesos\n"
     ]
    }
   ],
   "source": [
    "#attributes = [\"basiceps\", \"netincomediscontinued\", \"weightedavedilutedsharesos\", \"incometaxexpense\", \"netincometocommon\", \"cashdividendspershare\", \"totaloperatingincome\", \"weightedavebasicsharesos\", \"basicdilutedeps\", \"operatingcostofrevenue\", \"totalotherincome\", \"totalrevenue\", \"dilutedeps\", \"otherincome\", \"TAG\", \"totalgrossprofit\", \"rdexpense\", \"totalpretaxincome\", \"totaloperatingexpenses\", \"totalcostofrevenue\", \"weightedavebasicdilutedsharesos\", \"RESULT_COUNT: 26\", \"sgaexpense\", \"operatingrevenue\", \"totalinterestincome\", \"netincomecontinuing\", \"netincome\", \"totalinterestexpense\"]\n",
    "#print(len(attributes))\n",
    "\n",
    "# attributes = [\"ticker\", \"year\", \"quarter\", \"basicdilutedeps\", \"basiceps\", \"dilutedeps\", \"incometaxexpense\", \n",
    "#               \"netincome\",\"netincomecontinuing\", \"netincometocommon\", \"operatingcostofrevenue\",\"operatingrevenue\",\n",
    "#               \"otherincome\", \"rdexpense\", \"sgaexpense\", \"totalcostofrevenue\", \"totalgrossprofit\", \"totalinterestexpense\",\n",
    "#               \"totalinterestincome\", \"totaloperatingexpenses\", \"totaloperatingincome\", \"totalotherincome\", \n",
    "#               \"totalpretaxincome\", \"totalrevenue\", \"weightedavebasicdilutedsharesos\",\"weightedavebasicsharesos\", \n",
    "#               \"weightedavedilutedsharesos\"]\n",
    "attributes = [\"ticker\", \"year\", \"quarter\", \"basicdilutedeps\", \"basiceps\",\n",
    "              'cashdividendspershare', 'dilutedeps', 'incometaxexpense', 'netincome', 'netincomecontinuing',\n",
    "              'netincomediscontinued', 'netincometocommon', 'netincometononcontrollinginterest', 'totalcostofrevenue', \n",
    "                  'operatingcostofrevenue', 'operatingrevenue',\n",
    "              'othercostofrevenue', 'otherincome', 'preferreddividends', 'sgaexpense', \n",
    "              'totalgrossprofit', 'totalinterestexpense', 'totaloperatingexpenses', 'totaloperatingincome', 'totalotherincome', \n",
    "              'totalpretaxincome', 'totalrevenue', 'weightedavebasicdilutedsharesos', 'weightedavebasicsharesos', 'weightedavedilutedsharesos'\n",
    "                 ]\n",
    "print(len(attributes))\n",
    "\n",
    "xx = \",\".join(attributes)\n",
    "print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updated_intrinio_get_company_financials(symbol, year, quarter):\n",
    "        # Get the latest FY Income Statement for \"symbol\"\n",
    "        # 'type': 'FY'\n",
    "        cleanedupdata = {}\n",
    "        base_url = \"https://api.intrinio.com\"\n",
    "        request_url = base_url + \"/financials/standardized\"\n",
    "        query_params = {\n",
    "                'ticker': symbol,\n",
    "                'statement': 'income_statement',\n",
    "                'fiscal_year' : str(year),\n",
    "                'fiscal_period' : quarter\n",
    "        }\n",
    "\n",
    "        response = requests.get(request_url, params=query_params, auth=(INTRINIO_USERNAME, INTRINIO_PASSWORD))\n",
    "        if response.status_code == 401: print(\"Unauthorized! Check your username and password.\"); exit()\n",
    "\n",
    "        if response.status_code == 429:\n",
    "            print(\"API query limit reached\")\n",
    "            return\n",
    "        data = response.json()['data']\n",
    "\n",
    "        #print(data['basicdilutedeps'])\n",
    "        for row in data:\n",
    "                #print(row)\n",
    "                tag = row['tag']\n",
    "                value = row['value']\n",
    "\n",
    "                cleanedupdata[tag] = value\n",
    "                #print(tag + \": \" + str(value))\n",
    "#         for k, v in xx.items():\n",
    "#             print(k, v)\n",
    "        datalist=[]\n",
    "        attr = []\n",
    "        cleanedupdata[\"AASYMBOL\"] = symbol\n",
    "        cleanedupdata[\"ABYEAR\"] = year\n",
    "        cleanedupdata[\"ACPeriod\"] = quarter\n",
    "        cleanedupdata = updated_cleanupdata(cleanedupdata)\n",
    "        for key, value in sorted(cleanedupdata.items()):\n",
    "            datalist.append(str(value))\n",
    "            attr.append(str(key))\n",
    "        #return (json.dumps(cleanedupdata, indent=1, sort_keys=True))\n",
    "        #print(datalist)\n",
    "        #print(\"{}\".format(\"\".join(datalist)))\n",
    "        #return(\",\".join(datalist))\n",
    "        return(datalist, attr)\n",
    "#data = intrinio_get_company_financials('GE', '2010', 'FY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_financial_data():\n",
    "    SandP500 = {}\n",
    "    companyList = []\n",
    "    with open(\"SandP500_symbols.txt\", \"r\") as fr:\n",
    "            for line in fr:\n",
    "                    company = json.loads(line)\n",
    "                    SandP500[company[\"symbol\"]] = line\n",
    "                    companyList.append(company[\"symbol\"])\n",
    "\n",
    "    tickerchunks = [companyList[x:x+100] for x in xrange(0, len(companyList), 100)]\n",
    "\n",
    "    #print(\"Testing company financials api via CSV\")\n",
    "\n",
    "    years = [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017]\n",
    "    quarters = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"FY\"]\n",
    "    #years = [2010]\n",
    "    #quarters = [\"Q1\", \"Q2\"]\n",
    "    #companies = [\"GE\", \"CSCO\", \"GOOG\", \"FACE\"]\n",
    "\n",
    "    bigDict = {}\n",
    "\n",
    "    attributes = [\"ticker\", \"year\", \"quarter\", \"basicdilutedeps\", \"basiceps\",\n",
    "              'cashdividendspershare', 'dilutedeps', 'incometaxexpense', 'netincome', 'netincomecontinuing',\n",
    "              'netincomediscontinued', 'netincometocommon', 'netincometononcontrollinginterest', 'totalcostofrevenue', \n",
    "                  'operatingcostofrevenue', 'operatingrevenue',\n",
    "              'othercostofrevenue', 'otherincome', 'preferreddividends', 'sgaexpense', \n",
    "              'totalgrossprofit', 'totalinterestexpense', 'totaloperatingexpenses', 'totaloperatingincome', 'totalotherincome', \n",
    "              'totalpretaxincome', 'totalrevenue', 'weightedavebasicdilutedsharesos', 'weightedavebasicsharesos', 'weightedavedilutedsharesos'\n",
    "                 ]\n",
    "    print(len(attributes))\n",
    "\n",
    "    xx = \",\".join(attributes) + \"\\n\"\n",
    "\n",
    "    # tickerchunks[2] needs to be re-done with header line\n",
    "    for company in tickerchunks[3]:\n",
    "        with open(\"./revenue/\"+company+\"_Financials_by_Quarter.csv\", 'a') as fw:\n",
    "            fw.write(xx)\n",
    "            print(\"working on {}\".format(company))\n",
    "#             if loopindex > 2:\n",
    "#                 break\n",
    "#             loopindex += 1\n",
    "            #print(\"working on company {}\".format(company))\n",
    "            for year in years:\n",
    "                #bigDict[company][year] = {}\n",
    "                #print(\"working on year {}\".format(year))\n",
    "                for quarter in quarters:\n",
    "                    #print(\"working on quarter {}\".format(quarter))\n",
    "                    #bigDict[company][year][quarter] = {}\n",
    "                    data, _ = updated_intrinio_get_company_financials(company, str(year), quarter)\n",
    "                    yy = \",\".join(data)\n",
    "                    yy +=\"\\n\"\n",
    "                    #print(data)\n",
    "                    #print(\",\".join(data))\n",
    "                    fw.write(yy)\n",
    "\n",
    "            print(\"DONE with {}\".format(company))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "working on MMC\n",
      "DONE with MMC\n",
      "working on MLM\n",
      "DONE with MLM\n",
      "working on MAS\n",
      "DONE with MAS\n",
      "working on MA\n",
      "DONE with MA\n",
      "working on MAT\n",
      "DONE with MAT\n",
      "working on MKC\n",
      "DONE with MKC\n",
      "working on MCD\n",
      "DONE with MCD\n",
      "working on MCK\n",
      "DONE with MCK\n",
      "working on MDT\n",
      "DONE with MDT\n",
      "working on MRK\n",
      "DONE with MRK\n",
      "working on MET\n",
      "DONE with MET\n",
      "working on MTD\n",
      "DONE with MTD\n",
      "working on MGM\n",
      "DONE with MGM\n",
      "working on KORS\n",
      "DONE with KORS\n",
      "working on MCHP\n",
      "DONE with MCHP\n",
      "working on MU\n",
      "DONE with MU\n",
      "working on MSFT\n",
      "DONE with MSFT\n",
      "working on MAA\n",
      "DONE with MAA\n",
      "working on MHK\n",
      "DONE with MHK\n",
      "working on TAP\n",
      "DONE with TAP\n",
      "working on MDLZ\n",
      "DONE with MDLZ\n",
      "working on MON\n",
      "DONE with MON\n",
      "working on MNST\n",
      "DONE with MNST\n",
      "working on MCO\n",
      "DONE with MCO\n",
      "working on MS\n",
      "DONE with MS\n",
      "working on MOS\n",
      "DONE with MOS\n",
      "working on MSI\n",
      "DONE with MSI\n",
      "working on MYL\n",
      "DONE with MYL\n",
      "working on NDAQ\n",
      "DONE with NDAQ\n",
      "working on NOV\n",
      "DONE with NOV\n",
      "working on NAVI\n",
      "DONE with NAVI\n",
      "working on NTAP\n",
      "DONE with NTAP\n",
      "working on NFLX\n",
      "DONE with NFLX\n",
      "working on NWL\n",
      "DONE with NWL\n",
      "working on NFX\n",
      "DONE with NFX\n",
      "working on NEM\n",
      "DONE with NEM\n",
      "working on NWSA\n",
      "DONE with NWSA\n",
      "working on NWS\n",
      "DONE with NWS\n",
      "working on NEE\n",
      "DONE with NEE\n",
      "working on NLSN\n",
      "DONE with NLSN\n",
      "working on NKE\n",
      "DONE with NKE\n",
      "working on NI\n",
      "DONE with NI\n",
      "working on NBL\n",
      "DONE with NBL\n",
      "working on JWN\n",
      "DONE with JWN\n",
      "working on NSC\n",
      "DONE with NSC\n",
      "working on NTRS\n",
      "DONE with NTRS\n",
      "working on NOC\n",
      "DONE with NOC\n",
      "working on NRG\n",
      "DONE with NRG\n",
      "working on NUE\n",
      "DONE with NUE\n",
      "working on NVDA\n",
      "DONE with NVDA\n",
      "working on ORLY\n",
      "DONE with ORLY\n",
      "working on OXY\n",
      "DONE with OXY\n",
      "working on OMC\n",
      "DONE with OMC\n",
      "working on OKE\n",
      "DONE with OKE\n",
      "working on ORCL\n",
      "DONE with ORCL\n",
      "working on PCAR\n",
      "DONE with PCAR\n",
      "working on PKG\n",
      "DONE with PKG\n",
      "working on PH\n",
      "DONE with PH\n",
      "working on PDCO\n",
      "DONE with PDCO\n",
      "working on PAYX\n",
      "DONE with PAYX\n",
      "working on PYPL\n",
      "DONE with PYPL\n",
      "working on PNR\n",
      "DONE with PNR\n",
      "working on PBCT\n",
      "DONE with PBCT\n",
      "working on PEP\n",
      "DONE with PEP\n",
      "working on PKI\n",
      "DONE with PKI\n",
      "working on PRGO\n",
      "DONE with PRGO\n",
      "working on PFE\n",
      "DONE with PFE\n",
      "working on PCG\n",
      "DONE with PCG\n",
      "working on PM\n",
      "DONE with PM\n",
      "working on PSX\n",
      "DONE with PSX\n",
      "working on PNW\n",
      "DONE with PNW\n",
      "working on PXD\n",
      "DONE with PXD\n",
      "working on PNC\n",
      "DONE with PNC\n",
      "working on RL\n",
      "DONE with RL\n",
      "working on PPG\n",
      "DONE with PPG\n",
      "working on PPL\n",
      "DONE with PPL\n",
      "working on PX\n",
      "DONE with PX\n",
      "working on PCLN\n",
      "DONE with PCLN\n",
      "working on PFG\n",
      "DONE with PFG\n",
      "working on PG\n",
      "DONE with PG\n",
      "working on PGR\n",
      "DONE with PGR\n",
      "working on PLD\n",
      "DONE with PLD\n",
      "working on PRU\n",
      "DONE with PRU\n",
      "working on PEG\n",
      "DONE with PEG\n",
      "working on PSA\n",
      "DONE with PSA\n",
      "working on PHM\n",
      "DONE with PHM\n",
      "working on PVH\n",
      "DONE with PVH\n",
      "working on QRVO\n",
      "DONE with QRVO\n",
      "working on PWR\n",
      "DONE with PWR\n",
      "working on QCOM\n",
      "DONE with QCOM\n",
      "working on DGX\n",
      "DONE with DGX\n",
      "working on Q\n",
      "DONE with Q\n",
      "working on RRC\n",
      "DONE with RRC\n",
      "working on RJF\n",
      "DONE with RJF\n",
      "working on RTN\n",
      "DONE with RTN\n",
      "working on O\n",
      "DONE with O\n",
      "working on RHT\n",
      "DONE with RHT\n",
      "working on REG\n",
      "DONE with REG\n",
      "working on REGN\n",
      "DONE with REGN\n",
      "working on RF\n",
      "DONE with RF\n"
     ]
    }
   ],
   "source": [
    "generate_financial_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "attributes = [\"basiceps\", \"netincomediscontinued\", \"weightedavedilutedsharesos\", \"incometaxexpense\", \"netincometocommon\", \"cashdividendspershare\", \"totaloperatingincome\", \"weightedavebasicsharesos\", \"basicdilutedeps\", \"operatingcostofrevenue\", \"totalotherincome\", \"totalrevenue\", \"dilutedeps\", \"otherincome\", \"TAG\", \"totalgrossprofit\", \"rdexpense\", \"totalpretaxincome\", \"totaloperatingexpenses\", \"totalcostofrevenue\", \"weightedavebasicdilutedsharesos\", \"RESULT_COUNT: 26\", \"sgaexpense\", \"operatingrevenue\", \"totalinterestincome\", \"netincomecontinuing\", \"netincome\", \"totalinterestexpense\"]\n",
    "print(len(attributes))\n",
    "\n",
    "attributes = [\"ticker\", \"year\", \"quarter\", \"basicdilutedeps\", \"basiceps\", \"dilutedeps\", \"incometaxexpense\", \n",
    "              \"netincome\",\"netincomecontinuing\", \"netincometocommon\", \"operatingcostofrevenue\",\"operatingrevenue\",\n",
    "              \"otherincome\", \"rdexpense\", \"sgaexpense\", \"totalcostofrevenue\", \"totalgrossprofit\", \"totalinterestexpense\",\n",
    "              \"totalinterestincome\", \"totaloperatingexpenses\", \"totaloperatingincome\", \"totalotherincome\", \n",
    "              \"totalpretaxincome\", \"totalrevenue\", \"weightedavebasicdilutedsharesos\",\"weightedavebasicsharesos\", \n",
    "              \"weightedavedilutedsharesos\"]\n",
    "print(len(attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'attributes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7d1da0a4a6ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'attributes' is not defined"
     ]
    }
   ],
   "source": [
    "xx = \",\".join(attributes)\n",
    "print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/NatarajanShankar/UC_Berkeley/Final_term/Capstone/W210/MIDS_capstone/metadata\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/NatarajanShankar/UC_Berkeley/Final_term/Capstone/W210/MIDS_capstone/metadata\")\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import ast\n",
    "\n",
    "def convert_json_to_csv():\n",
    "    companyDict = {}\n",
    "    os.chdir(\"./data\")\n",
    "    #print(\"got here\")\n",
    "    for datafile in glob.glob(\"*Financials*.json\"):\n",
    "        #print(datafile)\n",
    "        with open(datafile, \"r\") as fr:\n",
    "            #print (\"Processing {}\".format(datafile))\n",
    "            for line in fr:\n",
    "                companyDict = ast.literal_eval(line)\n",
    "                \n",
    "                # Save company ticker\n",
    "                for company, companyvalue in companyDict.items():\n",
    "                    #print(\"Company is\")\n",
    "                    #print(\"{}\".format(company, end=''))\n",
    "                    # For every year subset\n",
    "                    if isinstance(companyvalue, dict):\n",
    "                        for year, yearvalue in companyvalue.items():\n",
    "                            #print(\"Year is\")\n",
    "                            #print(\"{}\".format(year, end=''))\n",
    "                            # Look at the corresponding quarter\n",
    "                            if isinstance(yearvalue, dict):\n",
    "                                datalist=[]\n",
    "                                # Look at company quarter\n",
    "                                for quarter, quartervalue in yearvalue.items():\n",
    "                                    #print(\"Quarter is\")\n",
    "                                    #print(\"{}\".format(quarter, end=''))\n",
    "                                    for financialdata in quartervalue.values():\n",
    "                                        datalist.append(financialdata)\n",
    "                                    \n",
    "                                    if len(datalist) > 21:\n",
    "                                        datalist[14] = \"IGNORE\"\n",
    "                                        datalist[21] = \"IGNORE\"\n",
    "                                    \n",
    "                                    if len(datalist) == 2:\n",
    "                                        datalist[0] = \"\"\n",
    "                                        datalist[1] = \"\"\n",
    "                                    print(\"{},{},{},{}\".format(company, year, quarter, \",\".join(datalist), end=''))\n",
    "                                    \n",
    "                                    datalist = []\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLIR,2010,Q1,\n",
      "FLIR,2010,Q4,\n"
     ]
    }
   ],
   "source": [
    "convert_json_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_company_financial_data_all(symbol):\n",
    "    companyDict = {}\n",
    "    with open(\"./data/Financials.json\", \"r\") as fp:\n",
    "        #companyDict = json.load(fp)\n",
    "        for line in fp:\n",
    "            companyDict = ast.literal_eval(line)\n",
    "\n",
    "        for ticker in companyDict.keys():\n",
    "            if ticker == symbol:\n",
    "                print symbol, companyDict[symbol]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_company_financial_data_all(\"GE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_company_financial_data_by_year(symbol, year):\n",
    "    companyDict = {}\n",
    "    with open(\"./data/Financials.json\", \"r\") as fp:\n",
    "        #companyDict = json.load(fp)\n",
    "        for line in fp:\n",
    "            companyDict = ast.literal_eval(line)\n",
    "\n",
    "        for ticker in companyDict.keys():\n",
    "            if ticker == symbol:\n",
    "                print symbol, companyDict[symbol][year]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_company_financial_data_by_year(\"GE\", \"2014\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_company_financial_data_by_year_and_attr(symbol, year, attribute):\n",
    "    companyDict = {}\n",
    "    with open(\"./data/Financials.json\", \"r\") as fp:\n",
    "        #companyDict = json.load(fp)\n",
    "        for line in fp:\n",
    "            companyDict = ast.literal_eval(line)\n",
    "\n",
    "        for ticker in companyDict.keys():\n",
    "            if ticker == symbol:\n",
    "                print symbol, companyDict[symbol][year][attribute]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_company_financial_data_by_year_and_attr(\"GE\", \"2014\", \"basiceps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_company_financial_data_csv(symbol):\n",
    "    companyDict = {}\n",
    "    with open(\"./data/Financials.json\", \"r\") as fp:\n",
    "        for line in fp:\n",
    "            companyDict = ast.literal_eval(line)\n",
    "            \n",
    "        for ticker in companyDict.keys():\n",
    "            if ticker == symbol:\n",
    "                print symbol, companyDict\n",
    "            \n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
