{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/NatarajanShankar/UC_Berkeley/Final_term/Capstone/W210/MIDS_capstone/metadata\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from api_key import INTRINIO_USERNAME\n",
    "from api_key import INTRINIO_PASSWORD             \n",
    "\n",
    "import md_intrinio_client\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from md_intrinio_client import intrinio_get_company_metadata\n",
    "from md_intrinio_client import intrinio_get_company_financials\n",
    "from md_intrinio_client import intrinio_get_company_financials_csv\n",
    "from md_intrinio_client import get_SandP_metadata\n",
    "from md_intrinio_client import test_SandP_metadata\n",
    "\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import finsymbols\n",
    "import ast\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/NatarajanShankar/UC_Berkeley/Final_term/Capstone/W210/MIDS_capstone/metadata\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('/home/skillachie/Desktop/')\n",
    "from finsymbols import symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json \n",
    "SandP500 = {}\n",
    "companyList = []\n",
    "with open(\"SandP500_symbols.txt\", \"r\") as fr:\n",
    "            for line in fr:\n",
    "                    company = json.loads(line)\n",
    "                    SandP500[company[\"symbol\"]] = line\n",
    "                    companyList.append(company[\"symbol\"])\n",
    "\n",
    "tickerchunks = [companyList[x:x+100] for x in xrange(0, len(companyList), 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[u'MMC', u'MLM', u'MAS', u'MA', u'MAT', u'MKC', u'MCD', u'MCK', u'MDT', u'MRK', u'MET', u'MTD', u'MGM', u'KORS', u'MCHP', u'MU', u'MSFT', u'MAA', u'MHK', u'TAP', u'MDLZ', u'MON', u'MNST', u'MCO', u'MS', u'MOS', u'MSI', u'MYL', u'NDAQ', u'NOV', u'NAVI', u'NTAP', u'NFLX', u'NWL', u'NFX', u'NEM', u'NWSA', u'NWS', u'NEE', u'NLSN', u'NKE', u'NI', u'NBL', u'JWN', u'NSC', u'NTRS', u'NOC', u'NRG', u'NUE', u'NVDA', u'ORLY', u'OXY', u'OMC', u'OKE', u'ORCL', u'PCAR', u'PKG', u'PH', u'PDCO', u'PAYX', u'PYPL', u'PNR', u'PBCT', u'PEP', u'PKI', u'PRGO', u'PFE', u'PCG', u'PM', u'PSX', u'PNW', u'PXD', u'PNC', u'RL', u'PPG', u'PPL', u'PX', u'PCLN', u'PFG', u'PG', u'PGR', u'PLD', u'PRU', u'PEG', u'PSA', u'PHM', u'PVH', u'QRVO', u'PWR', u'QCOM', u'DGX', u'Q', u'RRC', u'RJF', u'RTN', u'O', u'RHT', u'REG', u'REGN', u'RF']\n"
     ]
    }
   ],
   "source": [
    "print(len(tickerchunks[3]))\n",
    "print((tickerchunks[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def generate_financial_data():\n",
    "#     SandP500 = {}\n",
    "#     companyList = []\n",
    "#     with open(\"SandP500_symbols.txt\", \"r\") as fr:\n",
    "#             for line in fr:\n",
    "#                     company = json.loads(line)\n",
    "#                     SandP500[company[\"symbol\"]] = line\n",
    "#                     companyList.append(company[\"symbol\"])\n",
    "\n",
    "#     tickerchunks = [companyList[x:x+100] for x in xrange(0, len(companyList), 100)]\n",
    "\n",
    "#     #print(\"Testing company financials api via CSV\")\n",
    "\n",
    "#     #years = [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017]\n",
    "#     #quarters = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"FY\"]\n",
    "#     years = [2010]\n",
    "#     quarters = [\"Q1\", \"Q4\"]\n",
    "#     #companies = [\"GE\", \"CSCO\", \"GOOG\", \"FACE\"]\n",
    "\n",
    "#     bigDict = {}\n",
    "\n",
    "#     loopindex = 0\n",
    "#     for company in tickerchunks[2]:\n",
    "#         print(\"working on {}\".format(company))\n",
    "#         if loopindex > 2:\n",
    "#             break\n",
    "#         loopindex += 1\n",
    "#         bigDict[company] = {}\n",
    "#         #print(\"working on company {}\".format(company))\n",
    "#         for year in years:\n",
    "#             bigDict[company][year] = {}\n",
    "#             print(\"working on year {}\".format(year))\n",
    "#             for quarter in quarters:\n",
    "#                 print(\"working on quarter {}\".format(quarter))\n",
    "#                 bigDict[company][year][quarter] = {}\n",
    "#                 data = intrinio_get_company_financials_csv(company, str(year), quarter)\n",
    "#                 print(data)\n",
    "#                 financials = list(data)\n",
    "\n",
    "#                 print(\"FINANCIALS\")\n",
    "#                 print (financials)\n",
    "#                 breakdown = ''.join(financials)\n",
    "#                 #print(breakdown)\n",
    "#                 newdata = breakdown.split(\"\\n\")\n",
    "#                 print(newdata)\n",
    "#                 for item in newdata:\n",
    "#                     splititem = item.split(\",\")\n",
    "#                     if len(splititem) < 2:\n",
    "#                         continue\n",
    "#                     bigDict[company][year][quarter][splititem[0]]=  {}\n",
    "#                     bigDict[company][year][quarter][splititem[0]]= splititem[1]\n",
    "#         print(\"DONE with {}\".format(company))      \n",
    "        \n",
    "        \n",
    "#         print(\"Done with {}\".format(company))\n",
    "#         with open(\"./data/\"+company+\"_Financials_by_Quarter.json\", 'w') as fp:\n",
    "#             fp.write(json.dumps(bigDict))\n",
    "#             print(\"{}\".format(\"./data/\"+company+\"_Financials_by_Quarter.json\"))\n",
    "#             bigDict = {}\n",
    "#         return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_intrinio_get_company_financials(symbol, year, quarter):\n",
    "        # Get the latest FY Income Statement for \"symbol\"\n",
    "        # 'type': 'FY'\n",
    "        cleanedupdata = {}\n",
    "        base_url = \"https://api.intrinio.com\"\n",
    "        request_url = base_url + \"/financials/standardized\"\n",
    "        query_params = {\n",
    "                'ticker': symbol,\n",
    "                'statement': 'income_statement',\n",
    "                'fiscal_year' : str(year),\n",
    "                'fiscal_period' : quarter\n",
    "        }\n",
    "\n",
    "        response = requests.get(request_url, params=query_params, auth=(INTRINIO_USERNAME, INTRINIO_PASSWORD))\n",
    "        if response.status_code == 401: print(\"Unauthorized! Check your username and password.\"); exit()\n",
    "\n",
    "        if response.status_code == 429:\n",
    "            print(\"API query limit reached\")\n",
    "            return\n",
    "        data = response.json()['data']\n",
    "\n",
    "        #print(data['basicdilutedeps'])\n",
    "        for row in data:\n",
    "                tag = row['tag']\n",
    "                value = row['value']\n",
    "                cleanedupdata[\"AASYMBOL\"] = symbol\n",
    "                cleanedupdata[\"ABYEAR\"] = year\n",
    "                cleanedupdata[\"ACPeriod\"] = quarter\n",
    "                cleanedupdata[tag] = value\n",
    "                #print(tag + \": \" + str(value))\n",
    "#         for k, v in xx.items():\n",
    "#             print(k, v)\n",
    "        datalist=[]\n",
    "        for key, value in sorted(cleanedupdata.items()):\n",
    "            datalist.append(str(value))\n",
    "        \n",
    "        #print(json.dumps(cleanedupdata, indent=1, sort_keys=True))\n",
    "        #print(datalist)\n",
    "        #print(\"{}\".format(\"\".join(datalist)))\n",
    "        #return(\",\".join(datalist))\n",
    "        return(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updated_cleanupdata(cleanedupdata):\n",
    "    newData = {}\n",
    "    newData['AASYMBOL'] = cleanedupdata['AASYMBOL']\n",
    "    newData['ABYEAR'] = cleanedupdata['ABYEAR']\n",
    "    newData['ACPeriod'] = cleanedupdata['ACPeriod']\n",
    "    newData['basicdilutedeps'] = cleanedupdata.get('basicdilutedeps', 0.0)\n",
    "    newData['basiceps'] = cleanedupdata.get('basiceps', 0.0)\n",
    "    \n",
    "    newData['cashdividendspershare'] = cleanedupdata.get('cashdividendspershare', 0.0)\n",
    "    newData['dilutedeps'] = cleanedupdata.get('dilutedeps', 0.0)\n",
    "    newData['incometaxexpense'] = cleanedupdata.get('incometaxexpense', 0.0)\n",
    "    newData['netincome'] = cleanedupdata.get('netincome', 0.0)\n",
    "    newData['netincomecontinuing'] = cleanedupdata.get('netincomecontinuing', 0.0)\n",
    "    \n",
    "    newData['netincomediscontinued'] = cleanedupdata.get('netincomediscontinued', 0.0)\n",
    "    newData['netincometocommon'] = cleanedupdata.get('netincometocommon', 0.0)\n",
    "    newData['netincometononcontrollinginterest'] = cleanedupdata.get('netincometononcontrollinginterest', 0.0)\n",
    "    newData['operatingcostofrevenue'] = cleanedupdata.get('operatingcostofrevenue', 0.0)\n",
    "    newData['operatingrevenue'] = cleanedupdata.get('operatingrevenue', 0.0)\n",
    "    \n",
    "    newData['othercostofrevenue'] = cleanedupdata.get('othercostofrevenue', 0.0)\n",
    "    newData['otherincome'] = cleanedupdata.get('otherincome', 0.0)\n",
    "    newData['preferreddividends'] = cleanedupdata.get('preferreddividends', 0.0)\n",
    "    newData['sgaexpense'] = cleanedupdata.get('sgaexpense', 0.0)\n",
    "    newData['totalcostofrevenue'] = cleanedupdata.get('totalcostofrevenue', 0.0)\n",
    "    \n",
    "    newData['totalgrossprofit'] = cleanedupdata.get('totalgrossprofit', 0.0)\n",
    "    newData['totalinterestexpense'] = cleanedupdata.get('totalinterestexpense', 0.0)\n",
    "    newData['totaloperatingexpenses'] = cleanedupdata.get('totaloperatingexpenses', 0.0)\n",
    "    newData['totaloperatingincome'] = cleanedupdata.get('totaloperatingincome', 0.0)\n",
    "    newData['totalotherincome'] = cleanedupdata.get('totalotherincome', 0.0)\n",
    "    \n",
    "    newData['totalpretaxincome'] = cleanedupdata.get('totalpretaxincome', 0.0)\n",
    "    newData['totalrevenue'] = cleanedupdata.get('totalrevenue', 0.0)\n",
    "    newData['weightedavebasicdilutedsharesos'] = cleanedupdata.get('weightedavebasicdilutedsharesos', 0.0)\n",
    "    newData['weightedavebasicsharesos'] = cleanedupdata.get('weightedavebasicsharesos', 0.0)\n",
    "    newData['weightedavedilutedsharesos'] = cleanedupdata.get('weightedavedilutedsharesos', 0.0)\n",
    "    \n",
    "    #newData[] = cleanedupdata.get(, 0.0)\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "ticker,year,quarter,basicdilutedeps,basiceps,cashdividendspershare,dilutedeps,incometaxexpense,netincome,netincomecontinuing,netincomediscontinued,netincometocommon,netincometononcontrollinginterest,totalcostofrevenue,operatingcostofrevenue,operatingrevenue,othercostofrevenue,otherincome,preferreddividends,sgaexpense,totalgrossprofit,totalinterestexpense,totaloperatingexpenses,totaloperatingincome,totalotherincome,totalpretaxincome,totalrevenue,weightedavebasicdilutedsharesos,weightedavebasicsharesos,weightedavedilutedsharesos\n"
     ]
    }
   ],
   "source": [
    "#attributes = [\"basiceps\", \"netincomediscontinued\", \"weightedavedilutedsharesos\", \"incometaxexpense\", \"netincometocommon\", \"cashdividendspershare\", \"totaloperatingincome\", \"weightedavebasicsharesos\", \"basicdilutedeps\", \"operatingcostofrevenue\", \"totalotherincome\", \"totalrevenue\", \"dilutedeps\", \"otherincome\", \"TAG\", \"totalgrossprofit\", \"rdexpense\", \"totalpretaxincome\", \"totaloperatingexpenses\", \"totalcostofrevenue\", \"weightedavebasicdilutedsharesos\", \"RESULT_COUNT: 26\", \"sgaexpense\", \"operatingrevenue\", \"totalinterestincome\", \"netincomecontinuing\", \"netincome\", \"totalinterestexpense\"]\n",
    "#print(len(attributes))\n",
    "\n",
    "# attributes = [\"ticker\", \"year\", \"quarter\", \"basicdilutedeps\", \"basiceps\", \"dilutedeps\", \"incometaxexpense\", \n",
    "#               \"netincome\",\"netincomecontinuing\", \"netincometocommon\", \"operatingcostofrevenue\",\"operatingrevenue\",\n",
    "#               \"otherincome\", \"rdexpense\", \"sgaexpense\", \"totalcostofrevenue\", \"totalgrossprofit\", \"totalinterestexpense\",\n",
    "#               \"totalinterestincome\", \"totaloperatingexpenses\", \"totaloperatingincome\", \"totalotherincome\", \n",
    "#               \"totalpretaxincome\", \"totalrevenue\", \"weightedavebasicdilutedsharesos\",\"weightedavebasicsharesos\", \n",
    "#               \"weightedavedilutedsharesos\"]\n",
    "attributes = [\"ticker\", \"year\", \"quarter\", \"basicdilutedeps\", \"basiceps\",\n",
    "              'cashdividendspershare', 'dilutedeps', 'incometaxexpense', 'netincome', 'netincomecontinuing',\n",
    "              'netincomediscontinued', 'netincometocommon', 'netincometononcontrollinginterest', 'totalcostofrevenue', \n",
    "                  'operatingcostofrevenue', 'operatingrevenue',\n",
    "              'othercostofrevenue', 'otherincome', 'preferreddividends', 'sgaexpense', \n",
    "              'totalgrossprofit', 'totalinterestexpense', 'totaloperatingexpenses', 'totaloperatingincome', 'totalotherincome', \n",
    "              'totalpretaxincome', 'totalrevenue', 'weightedavebasicdilutedsharesos', 'weightedavebasicsharesos', 'weightedavedilutedsharesos'\n",
    "                 ]\n",
    "print(len(attributes))\n",
    "\n",
    "xx = \",\".join(attributes)\n",
    "print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updated_intrinio_get_company_financials(symbol, year, quarter):\n",
    "        # Get the latest FY Income Statement for \"symbol\"\n",
    "        # 'type': 'FY'\n",
    "        cleanedupdata = {}\n",
    "        base_url = \"https://api.intrinio.com\"\n",
    "        request_url = base_url + \"/financials/standardized\"\n",
    "        query_params = {\n",
    "                'ticker': symbol,\n",
    "                'statement': 'income_statement',\n",
    "                'fiscal_year' : str(year),\n",
    "                'fiscal_period' : quarter\n",
    "        }\n",
    "\n",
    "        response = requests.get(request_url, params=query_params, auth=(INTRINIO_USERNAME, INTRINIO_PASSWORD))\n",
    "        if response.status_code == 401: print(\"Unauthorized! Check your username and password.\"); exit()\n",
    "\n",
    "        if response.status_code == 429:\n",
    "            print(\"API query limit reached\")\n",
    "            return\n",
    "        data = response.json()['data']\n",
    "\n",
    "        #print(data['basicdilutedeps'])\n",
    "        for row in data:\n",
    "                #print(row)\n",
    "                tag = row['tag']\n",
    "                value = row['value']\n",
    "\n",
    "                cleanedupdata[tag] = value\n",
    "                #print(tag + \": \" + str(value))\n",
    "#         for k, v in xx.items():\n",
    "#             print(k, v)\n",
    "        datalist=[]\n",
    "        attr = []\n",
    "        cleanedupdata[\"AASYMBOL\"] = symbol\n",
    "        cleanedupdata[\"ABYEAR\"] = year\n",
    "        cleanedupdata[\"ACPeriod\"] = quarter\n",
    "        cleanedupdata = updated_cleanupdata(cleanedupdata)\n",
    "        for key, value in sorted(cleanedupdata.items()):\n",
    "            datalist.append(str(value))\n",
    "            attr.append(str(key))\n",
    "        #return (json.dumps(cleanedupdata, indent=1, sort_keys=True))\n",
    "        #print(datalist)\n",
    "        #print(\"{}\".format(\"\".join(datalist)))\n",
    "        #return(\",\".join(datalist))\n",
    "        return(datalist, attr)\n",
    "#data = intrinio_get_company_financials('GE', '2010', 'FY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_financial_data():\n",
    "    SandP500 = {}\n",
    "    companyList = []\n",
    "    with open(\"SandP500_symbols.txt\", \"r\") as fr:\n",
    "            for line in fr:\n",
    "                    company = json.loads(line)\n",
    "                    SandP500[company[\"symbol\"]] = line\n",
    "                    companyList.append(company[\"symbol\"])\n",
    "\n",
    "    tickerchunks = [companyList[x:x+100] for x in xrange(0, len(companyList), 100)]\n",
    "\n",
    "    #print(\"Testing company financials api via CSV\")\n",
    "\n",
    "    years = [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017]\n",
    "    quarters = [\"Q1\", \"Q2\", \"Q3\", \"Q4\", \"FY\"]\n",
    "    #years = [2010]\n",
    "    #quarters = [\"Q1\", \"Q2\"]\n",
    "    #companies = [\"GE\", \"CSCO\", \"GOOG\", \"FACE\"]\n",
    "\n",
    "    bigDict = {}\n",
    "\n",
    "    attributes = [\"ticker\", \"year\", \"quarter\", \"basicdilutedeps\", \"basiceps\",\n",
    "              'cashdividendspershare', 'dilutedeps', 'incometaxexpense', 'netincome', 'netincomecontinuing',\n",
    "              'netincomediscontinued', 'netincometocommon', 'netincometononcontrollinginterest', 'totalcostofrevenue', \n",
    "                  'operatingcostofrevenue', 'operatingrevenue',\n",
    "              'othercostofrevenue', 'otherincome', 'preferreddividends', 'sgaexpense', \n",
    "              'totalgrossprofit', 'totalinterestexpense', 'totaloperatingexpenses', 'totaloperatingincome', 'totalotherincome', \n",
    "              'totalpretaxincome', 'totalrevenue', 'weightedavebasicdilutedsharesos', 'weightedavebasicsharesos', 'weightedavedilutedsharesos'\n",
    "                 ]\n",
    "    print(len(attributes))\n",
    "\n",
    "    xx = \",\".join(attributes) + \"\\n\"\n",
    "\n",
    "    # tickerchunks[2] needs to be re-done with header line\n",
    "    for company in tickerchunks[3]:\n",
    "        with open(\"./revenue/\"+company+\"_Financials_by_Quarter.csv\", 'a') as fw:\n",
    "            fw.write(xx)\n",
    "            print(\"working on {}\".format(company))\n",
    "#             if loopindex > 2:\n",
    "#                 break\n",
    "#             loopindex += 1\n",
    "            #print(\"working on company {}\".format(company))\n",
    "            for year in years:\n",
    "                #bigDict[company][year] = {}\n",
    "                #print(\"working on year {}\".format(year))\n",
    "                for quarter in quarters:\n",
    "                    #print(\"working on quarter {}\".format(quarter))\n",
    "                    #bigDict[company][year][quarter] = {}\n",
    "                    data, _ = updated_intrinio_get_company_financials(company, str(year), quarter)\n",
    "                    yy = \",\".join(data)\n",
    "                    yy +=\"\\n\"\n",
    "                    #print(data)\n",
    "                    #print(\",\".join(data))\n",
    "                    fw.write(yy)\n",
    "\n",
    "            print(\"DONE with {}\".format(company))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "working on MMC\n",
      "working on year 2010\n",
      "working on quarter Q1\n",
      "working on quarter Q2\n",
      "DONE with MMC\n"
     ]
    }
   ],
   "source": [
    "generate_financial_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "attributes = [\"basiceps\", \"netincomediscontinued\", \"weightedavedilutedsharesos\", \"incometaxexpense\", \"netincometocommon\", \"cashdividendspershare\", \"totaloperatingincome\", \"weightedavebasicsharesos\", \"basicdilutedeps\", \"operatingcostofrevenue\", \"totalotherincome\", \"totalrevenue\", \"dilutedeps\", \"otherincome\", \"TAG\", \"totalgrossprofit\", \"rdexpense\", \"totalpretaxincome\", \"totaloperatingexpenses\", \"totalcostofrevenue\", \"weightedavebasicdilutedsharesos\", \"RESULT_COUNT: 26\", \"sgaexpense\", \"operatingrevenue\", \"totalinterestincome\", \"netincomecontinuing\", \"netincome\", \"totalinterestexpense\"]\n",
    "print(len(attributes))\n",
    "\n",
    "attributes = [\"ticker\", \"year\", \"quarter\", \"basicdilutedeps\", \"basiceps\", \"dilutedeps\", \"incometaxexpense\", \n",
    "              \"netincome\",\"netincomecontinuing\", \"netincometocommon\", \"operatingcostofrevenue\",\"operatingrevenue\",\n",
    "              \"otherincome\", \"rdexpense\", \"sgaexpense\", \"totalcostofrevenue\", \"totalgrossprofit\", \"totalinterestexpense\",\n",
    "              \"totalinterestincome\", \"totaloperatingexpenses\", \"totaloperatingincome\", \"totalotherincome\", \n",
    "              \"totalpretaxincome\", \"totalrevenue\", \"weightedavebasicdilutedsharesos\",\"weightedavebasicsharesos\", \n",
    "              \"weightedavedilutedsharesos\"]\n",
    "print(len(attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'attributes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7d1da0a4a6ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'attributes' is not defined"
     ]
    }
   ],
   "source": [
    "xx = \",\".join(attributes)\n",
    "print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/NatarajanShankar/UC_Berkeley/Final_term/Capstone/W210/MIDS_capstone/metadata\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/NatarajanShankar/UC_Berkeley/Final_term/Capstone/W210/MIDS_capstone/metadata\")\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import ast\n",
    "\n",
    "def convert_json_to_csv():\n",
    "    companyDict = {}\n",
    "    os.chdir(\"./data\")\n",
    "    #print(\"got here\")\n",
    "    for datafile in glob.glob(\"*Financials*.json\"):\n",
    "        #print(datafile)\n",
    "        with open(datafile, \"r\") as fr:\n",
    "            #print (\"Processing {}\".format(datafile))\n",
    "            for line in fr:\n",
    "                companyDict = ast.literal_eval(line)\n",
    "                \n",
    "                # Save company ticker\n",
    "                for company, companyvalue in companyDict.items():\n",
    "                    #print(\"Company is\")\n",
    "                    #print(\"{}\".format(company, end=''))\n",
    "                    # For every year subset\n",
    "                    if isinstance(companyvalue, dict):\n",
    "                        for year, yearvalue in companyvalue.items():\n",
    "                            #print(\"Year is\")\n",
    "                            #print(\"{}\".format(year, end=''))\n",
    "                            # Look at the corresponding quarter\n",
    "                            if isinstance(yearvalue, dict):\n",
    "                                datalist=[]\n",
    "                                # Look at company quarter\n",
    "                                for quarter, quartervalue in yearvalue.items():\n",
    "                                    #print(\"Quarter is\")\n",
    "                                    #print(\"{}\".format(quarter, end=''))\n",
    "                                    for financialdata in quartervalue.values():\n",
    "                                        datalist.append(financialdata)\n",
    "                                    \n",
    "                                    if len(datalist) > 21:\n",
    "                                        datalist[14] = \"IGNORE\"\n",
    "                                        datalist[21] = \"IGNORE\"\n",
    "                                    \n",
    "                                    if len(datalist) == 2:\n",
    "                                        datalist[0] = \"\"\n",
    "                                        datalist[1] = \"\"\n",
    "                                    print(\"{},{},{},{}\".format(company, year, quarter, \",\".join(datalist), end=''))\n",
    "                                    \n",
    "                                    datalist = []\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLIR,2010,Q1,\n",
      "FLIR,2010,Q4,\n"
     ]
    }
   ],
   "source": [
    "convert_json_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_company_financial_data_all(symbol):\n",
    "    companyDict = {}\n",
    "    with open(\"./data/Financials.json\", \"r\") as fp:\n",
    "        #companyDict = json.load(fp)\n",
    "        for line in fp:\n",
    "            companyDict = ast.literal_eval(line)\n",
    "\n",
    "        for ticker in companyDict.keys():\n",
    "            if ticker == symbol:\n",
    "                print symbol, companyDict[symbol]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_company_financial_data_all(\"GE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_company_financial_data_by_year(symbol, year):\n",
    "    companyDict = {}\n",
    "    with open(\"./data/Financials.json\", \"r\") as fp:\n",
    "        #companyDict = json.load(fp)\n",
    "        for line in fp:\n",
    "            companyDict = ast.literal_eval(line)\n",
    "\n",
    "        for ticker in companyDict.keys():\n",
    "            if ticker == symbol:\n",
    "                print symbol, companyDict[symbol][year]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_company_financial_data_by_year(\"GE\", \"2014\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_company_financial_data_by_year_and_attr(symbol, year, attribute):\n",
    "    companyDict = {}\n",
    "    with open(\"./data/Financials.json\", \"r\") as fp:\n",
    "        #companyDict = json.load(fp)\n",
    "        for line in fp:\n",
    "            companyDict = ast.literal_eval(line)\n",
    "\n",
    "        for ticker in companyDict.keys():\n",
    "            if ticker == symbol:\n",
    "                print symbol, companyDict[symbol][year][attribute]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_company_financial_data_by_year_and_attr(\"GE\", \"2014\", \"basiceps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_company_financial_data_csv(symbol):\n",
    "    companyDict = {}\n",
    "    with open(\"./data/Financials.json\", \"r\") as fp:\n",
    "        for line in fp:\n",
    "            companyDict = ast.literal_eval(line)\n",
    "            \n",
    "        for ticker in companyDict.keys():\n",
    "            if ticker == symbol:\n",
    "                print symbol, companyDict\n",
    "            \n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
